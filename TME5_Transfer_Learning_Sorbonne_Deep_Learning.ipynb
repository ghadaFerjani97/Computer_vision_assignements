{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbzBJ1m9FBBb"
   },
   "source": [
    "# Attention : \n",
    "# Faire \"File -> Save a copy in Drive\" avant de commencer à modifier le notebook, sinon vos modifications ne seront pas sauvegardées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aO2MIqZcrhCQ"
   },
   "source": [
    "Avant de commencer le TP, vérifiez que vous êtes sur un environnement GPU et python 3 : \n",
    "\n",
    "Exécution -> Modifier le type d'exécution -> Type d'exécution = python2, Accélerateur matériel = GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hubU7zZbAz4a"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ofov1WtQ64_p"
   },
   "source": [
    "# Partie 1 : Architecture VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4eQjntfb5wI0",
    "outputId": "4e46a85d-930f-49ba-b09b-ba8149c1c35a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-27 14:11:18--  https://github.com/cdancette/deep-learning-polytech-tp6-7/raw/master/tp8/imagenet_classes.pkl\n",
      "Résolution de github.com (github.com)… 140.82.121.4\n",
      "Connexion à github.com (github.com)|140.82.121.4|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 302 Found\n",
      "Emplacement : https://raw.githubusercontent.com/cdancette/deep-learning-polytech-tp6-7/master/tp8/imagenet_classes.pkl [suivant]\n",
      "--2021-01-27 14:11:21--  https://raw.githubusercontent.com/cdancette/deep-learning-polytech-tp6-7/master/tp8/imagenet_classes.pkl\n",
      "Résolution de raw.githubusercontent.com (raw.githubusercontent.com)… 151.101.120.133\n",
      "Connexion à raw.githubusercontent.com (raw.githubusercontent.com)|151.101.120.133|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 35454 (35K) [text/plain]\n",
      "Enregistre : «imagenet_classes.pkl.1»\n",
      "\n",
      "imagenet_classes.pk 100%[===================>]  34,62K  --.-KB/s    ds 0,08s   \n",
      "\n",
      "2021-01-27 14:11:22 (426 KB/s) - «imagenet_classes.pkl.1» enregistré [35454/35454]\n",
      "\n",
      "--2021-01-27 14:11:22--  https://unsplash.com/photos/gKXKBY-C-Dk/download?force=true\n",
      "Résolution de unsplash.com (unsplash.com)… 151.101.193.181, 151.101.65.181, 151.101.129.181, ...\n",
      "Connexion à unsplash.com (unsplash.com)|151.101.193.181|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 302 Found\n",
      "Emplacement : https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&dl=manja-vitolic-gKXKBY-C-Dk-unsplash.jpg [suivant]\n",
      "--2021-01-27 14:11:26--  https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&dl=manja-vitolic-gKXKBY-C-Dk-unsplash.jpg\n",
      "Résolution de images.unsplash.com (images.unsplash.com)… échec : Nom ou service inconnu.\n",
      "wget : impossible de résoudre l’adresse de l’hôte «images.unsplash.com»\n",
      "--2021-01-27 14:11:26--  https://unsplash.com/photos/qO-PIF84Vxg/download?force=true\n",
      "Résolution de unsplash.com (unsplash.com)… échec : Nom ou service inconnu.\n",
      "wget : impossible de résoudre l’adresse de l’hôte «unsplash.com»\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/cdancette/deep-learning-polytech-tp6-7/raw/master/tp8/imagenet_classes.pkl\n",
    "\n",
    "# Bonus : Classifiez des exemples avec vgg16 et commentez le résultat dans votre rapport.\n",
    "!wget --content-disposition https://unsplash.com/photos/gKXKBY-C-Dk/download?force=true -O cat.jpg\n",
    "!wget --content-disposition https://unsplash.com/photos/qO-PIF84Vxg/download?force=true -O dog.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://webia.lip6.fr/~robert/cours/rdfia/vgg16-397923af.pth\" to /tmp/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428da38d39bb4c86b4d8112365068ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torchvision.models.vgg.model_urls[\"vgg16\"] = \"http://webia.lip6.fr/~robert/cours/rdfia/vgg16-397923af.pth\"\n",
    "os.environ[\"TORCH_HOME\"] = \"/tmp/torch\"\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "vgg16.eval() \n",
    "imagenet_classes = pickle.load(open('imagenet_classes.pkl', 'rb'))\n",
    "img = PIL.Image.open(\"dog.jpg\")\n",
    "img = img.resize((224, 224), PIL.Image.BILINEAR)\n",
    "img = np.array(img, dtype=np.float32) / 255\n",
    "img = img.transpose((2, 0, 1))\n",
    "\n",
    "img = np.expand_dims(img, 0) # transformer en batch contenant une image\n",
    "x = torch.Tensor(img)\n",
    "\n",
    "y = vgg16.forward(x)\n",
    "y = y.detach() # transformation en array numpy\n",
    "y=y.numpy()\n",
    "# TODO récupérer la classe prédite et son score de confiance\n",
    "print(type(imagenet_classes))\n",
    "print(\"la classe prédite est \",imagenet_classes[np.argmax(y)])\n",
    "print('le score de confiance est',np.max(y))\n",
    "print(vgg16.features[0](x).shape)\n",
    "\n",
    "plt.imshow(vgg16.features[0](x)[0][0].detach())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQO8iQd26okS"
   },
   "source": [
    "# Partie 2: Transfer Learning avec VGG16 sur 15 Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vonhfnKF61bg"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/cdancette/deep-learning-polytech-tp6-7/raw/master/tp8/15ScenesData.zip\n",
    "!unzip 15ScenesData.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blP1Sj_0DXVd"
   },
   "outputs": [],
   "source": [
    "ls 15SceneData/test/bedroom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooU4YUoYNxMa"
   },
   "outputs": [],
   "source": [
    "class VGG16relu7(torch.nn.Module):\n",
    "    def __init__(self,vgg16):\n",
    "        super(VGG16relu7,self).__init__()\n",
    "        self.features = torch.nn.Sequential(*list(vgg16.features.children()))\n",
    "        self.classifier = torch.nn.Sequential(*list(vgg16.classifier.children())[:-2])\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.classifier(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKmqYMPErn4p"
   },
   "outputs": [],
   "source": [
    "\n",
    "PRINT_INTERVAL = 50\n",
    "CUDA = True\n",
    "\n",
    "def get_dataset(batch_size, path):\n",
    "\n",
    "    def duplicateChannel(img):\n",
    "        # Cette fonction permet de recopier 3 fois une image qui\n",
    "        # ne serait que sur 1 channel (donc image niveau de gris)\n",
    "        # pour la \"transformer\" en image RGB. Utilisez la avec\n",
    "        # transform.Lambda\n",
    "        img = img.convert('L')\n",
    "        np_img = np.array(img, dtype=np.uint8)\n",
    "        np_img = np.dstack([np_img, np_img, np_img])\n",
    "        img = Image.fromarray(np_img, 'RGB')\n",
    "        return img\n",
    "\n",
    "    mu,sigma = [0.485,0.456,0.406],[0.229,0.224,0.225]\n",
    "    train_dataset = datasets.ImageFolder(path+'/train',\n",
    "        transform=transforms.Compose([ # TODO Pré-traitement à faire\n",
    "            transforms.Resize(256),                    #[2]\n",
    "            transforms.CenterCrop(224), \n",
    "            transforms.Lambda(duplicateChannel),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mu,sigma, inplace=True)\n",
    "        ]))\n",
    "    val_dataset = datasets.ImageFolder(path+'/test',\n",
    "        transform=transforms.Compose([ # TODO Pré-traitement à faire\n",
    "            transforms.Resize(256),                    #[2]\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Lambda(duplicateChannel),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mu,sigma, inplace=True)\n",
    "        ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                        batch_size=batch_size, shuffle=False, pin_memory=CUDA, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                        batch_size=batch_size, shuffle=False, pin_memory=CUDA, num_workers=2)\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztOwrr0IrvGy"
   },
   "outputs": [],
   "source": [
    "def extract_features(data, model):\n",
    "    # TODO init features matrices\n",
    "    X = np.zeros((len(data),data.batch_size,4096)) # 4096 dimension de l'avant derniere couche de VGG16.\n",
    "    y = np.zeros((len(data),data.batch_size))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, target) in enumerate(data):\n",
    "            if i % PRINT_INTERVAL == 0:\n",
    "                print('Batch {0:03d}/{1:03d}'.format(i, len(data)))\n",
    "            if CUDA:\n",
    "                x = x.cuda()\n",
    "            \n",
    "            features = model(x)\n",
    "            try:\n",
    "                X[i] = features.detach().numpy()\n",
    "                y[i]=target.detach().numpy()\n",
    "            except:\n",
    "                print(\"on ignore l'itération : \",i)\n",
    "            print(\"i=\",i)\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "def reshape_no_batch(X,y):\n",
    "    # Enleve les batch et reshape les données numpy. \n",
    "    X = X.reshape((X.shape[0]*X.shape[1],X.shape[2]))\n",
    "    y = y.reshape((y.shape[0]*y.shape[1]))\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def main(path=\"15SceneData\", batch_size=8):\n",
    "   \n",
    "    # Paramètres en ligne de commande\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--path', default='15SceneData', type=str, metavar='DIR', help='path to dataset')\n",
    "    parser.add_argument('--batch-size', default=20, type=int, metavar='N', help='mini-batch size (default: 8)')\n",
    "    parser.add_argument('--cuda', dest='cuda', action='store_true', help='activate GPU acceleration')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    if args.cuda:\n",
    "        CUDA = True\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    #main(args)\n",
    "    params = args\n",
    "    print('Instanciation de VGG16')\n",
    "    vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "    print('Instanciation de VGG16relu7')\n",
    "    model = VGG16relu7(vgg16) # TODO À remplacer par un reseau tronché pour faire de la feature extraction\n",
    "\n",
    "    model.eval()\n",
    "    if CUDA: # si on fait du GPU, passage en CUDA\n",
    "        model = model.cuda()\n",
    "\n",
    "    # On récupère les données\n",
    "    print('Récupération des données')\n",
    "    train, test = get_dataset(params.batch_size, params.path)\n",
    "\n",
    "    # Extraction des features\n",
    "    print('Feature extraction')\n",
    "    if not os.path.exists('numpy_object/X_train.npy') : \n",
    "        X_train, y_train = extract_features(train, model)\n",
    "        np.save('numpy_object/X_train.npy', X_train)\n",
    "        np.save('numpy_object/y_train.npy', y_train)\n",
    "    else:\n",
    "        print(\"Chargement des fichiers X_train.npy et y_train.npy\")\n",
    "        X_train = np.load('numpy_object/X_train.npy')\n",
    "        y_train = np.load('numpy_object/y_train.npy')\n",
    "\n",
    "    X_train,y_train = reshape_no_batch(X_train,y_train)\n",
    "\n",
    "    if not os.path.exists('numpy_object/X_test.npy') : \n",
    "        X_test, y_test = extract_features(test, model)\n",
    "        np.save('numpy_object/X_test.npy', X_test)\n",
    "        np.save('numpy_object/y_test.npy', y_test)\n",
    "    else:\n",
    "        X_test = np.load('numpy_object/X_test.npy')\n",
    "        y_test = np.load('numpy_object/y_test.npy')\n",
    "\n",
    "    X_test,y_test = reshape_no_batch(X_test,y_test)\n",
    "    \n",
    "\n",
    "    # TODO Apprentissage et évaluation des SVM à faire\n",
    "    print('Apprentissage des SVM')\n",
    "    svm = LinearSVC(C=1.0)\n",
    "    svm.fit(X_train,y_train)\n",
    "    accuracy = svm.score(X_test,y_test)\n",
    "    print(\"SVM accuraccy C=1 :\",accuracy)\n",
    "\n",
    "    liste_C = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]\n",
    "    accuracy = []\n",
    "    for c in liste_C:\n",
    "\n",
    "        svm = LinearSVC(C=c)\n",
    "        svm.fit(X_train,y_train)\n",
    "        accuracy.append(svm.score(X_test,y_test))\n",
    "    \n",
    "    plt.plot(liste_C,accuracy)\n",
    "    plt.ylabel('SVM Accuracy')\n",
    "    plt.xlabel('paramètre C')\n",
    "    plt.title('Exploration du paramètre C du SVM.')\n",
    "    plt.show()\n",
    "    \n",
    "    input(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMh4ih-QvjOd"
   },
   "outputs": [],
   "source": [
    "main(\"15SceneData\", 8)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de TP 7 - Transfer Learning - Sorbonne - Deep Learning",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
