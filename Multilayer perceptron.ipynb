{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tp8_NADA_HAJSALAH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvRESaF5Cp-s"
      },
      "source": [
        "#!pip install optuna\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import optuna\n",
        "from sklearn.externals import joblib\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL8JAHbpk0E1"
      },
      "source": [
        "**Loading Data and subsampling:**\r\n",
        "\r\n",
        "For training, we keep only 5% of the available sample so that we can easily overfit and thus observe the impact of regularization techniques later.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqsvjBa3YGRP"
      },
      "source": [
        "batch_size = 300\r\n",
        "\r\n",
        "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\r\n",
        "trainset = datasets.MNIST('../data', train=True, download=True, transform=transform)\r\n",
        "subsample = np.random.choice(range(len(trainset)), size=int(len(trainset)*0.05))\r\n",
        "rest = list(set(range(len(trainset))).difference(set(subsample)))\r\n",
        "trainset_ = torch.utils.data.Subset(trainset, subsample)\r\n",
        "restset = torch.utils.data.Subset(trainset, rest)\r\n",
        "train_loader = torch.utils.data.DataLoader(trainset_, batch_size)\r\n",
        "valset = datasets.MNIST('../data', train=False, transform=transform)\r\n",
        "val_loader = torch.utils.data.DataLoader(valset, batch_size)\r\n",
        "rest_loader = torch.utils.data.DataLoader(restset, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9SMf8gwk7Mf",
        "outputId": "169fca4e-f46a-42e1-c69c-f087de8c20d7"
      },
      "source": [
        "print(\"examples kept for later fine-tuning of hyperparameters: (95%)\", len(restset))\r\n",
        "print(\"training examples: (5%) \", len(trainset_))\r\n",
        "print(\"validation examples: \", len(valset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "examples kept for later fine-tuning of hyperparameters: (95%) 57070\n",
            "training examples: (5%)  3000\n",
            "validation examples:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqEVeu6YkkeT"
      },
      "source": [
        "**Definition of the core network:** \r\n",
        "\r\n",
        "An MLP with 3 hidden **linear** layers (100 units each, relu activation), and an **output** layer of dim 10 (softmaxed) for multilaclass classifciation purpose. \r\n",
        "\r\n",
        "By setting\r\n",
        "\r\n",
        "- useDropout = float: we activate dropout over 2nd and 3rd linear layers. (the dorpout proba is given by the float value useDropout)\r\n",
        "- useBN = float: we activate batch normalization over 1st, 2nd and 3rd linear layers. (epsilon is stored in useBN)\r\n",
        "- useL1/L2 = float: we activate L1/L2 regularizations. (reg parameters are specified in the useL1/useL2 args)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00MVRdJJ3WGm"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, useDropout=None, useBN=None, useL1=None, useL2=None):\n",
        "        \n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(28*28, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.out = nn.Linear(100, 10)\n",
        "        \n",
        "        self.useDropout = useDropout\n",
        "        self.useBN = useBN\n",
        "        self.useL1 = useL1\n",
        "        self.useL2 = useL2\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.view(-1, 28*28)\n",
        "        #layer 1, [batchnorm]\n",
        "        x = self.fc1(x)\n",
        "        if self.useBN is not None:\n",
        "            x = nn.BatchNorm1d(num_features=100, eps=self.useBN)(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #layer 2, [batchnorm, dropout]\n",
        "        x = self.fc2(x)\n",
        "        if self.useBN is not None:\n",
        "            x = nn.BatchNorm1d(num_features=100, eps=self.useBN)(x)\n",
        "        x = F.relu(x)\n",
        "        if self.useDropout is not None:\n",
        "            x = F.dropout(x, p=float(self.useDropout))\n",
        "\n",
        "        #layer 3, [batchnorm, dropout]\n",
        "        x = self.fc3(x)\n",
        "        if self.useBN is not None:\n",
        "            x = nn.BatchNorm1d(num_features=100, eps=self.useBN)(x)\n",
        "        x = F.relu(x)\n",
        "        if self.useDropout is not None:\n",
        "            x = F.dropout(x, p=float(self.useDropout))\n",
        "\n",
        "        #out, softmax\n",
        "        x = self.out(x)\n",
        "        output = F.softmax(x, dim=0)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLYKjoQlJm0"
      },
      "source": [
        "At this level, we should define the training/validation loops. For that, we use `model.train()` or `model.eval()` (which allows turning on/off the units when using dropout for example). When training, we use torch.utils.tensorboard to save:\r\n",
        "\r\n",
        "    The costs (train, validation).\r\n",
        "    The weights of each linear layer (histogram).\r\n",
        "    The gradient at the entrance of each linear layer\r\n",
        "\r\n",
        "We avoid recording histograms at each iteration; we save twenty at most during the training in order to save storage space and computing time.\r\n",
        "\r\n",
        "We distinguish two modes of functionning for the model \"train mode\" set via net.train() and \"evaluation mode\" set via net.eval() (this allows for instance taking into account the dropout, batchnormalization when training but restore things back when infering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6O1m4Sr20WV"
      },
      "source": [
        "def train(log_interval, model, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    cnt_loss_train = 0\n",
        "    for batch_idx, (img_batch, label_batch) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output_batch = model(img_batch)\n",
        "        loss = criterion(input=output_batch, target=label_batch)\n",
        "        loss.backward()\n",
        "        writer.add_scalars('Loss',{'train':loss}, cnt_loss_train)\n",
        "        cnt_loss_train += 1\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "          print('Train Epoch: {} Loss: {:.6f}'.format(\n",
        "                epoch , loss.item()))\n",
        "    if epoch % 50 == 0:\n",
        "        for name, param in model.named_parameters() :\n",
        "            if name == \"fc1.weight\" or name == \"fc1.bias\":\n",
        "                writer.add_histogram(name, param.data.view(-1), epoch//50)\n",
        "            if name == \"fc2.weight\" or name == \"fc2.bias\":\n",
        "                writer.add_histogram(name, param.data.view(-1), epoch//50)\n",
        "            if name == \"fc3.weight\" or name == 'fc3.bias':\n",
        "                writer.add_histogram(name, param.data.view(-1), epoch//50)\n",
        "            writer.add_histogram(name + '_grad', param.grad, epoch//50)  \n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    cnt_loss_val = 0\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target).item()\n",
        "            test_loss += loss  # sum up batch loss\n",
        "            writer.add_scalars('Loss',{'eval':loss}, cnt_loss_val)\n",
        "            cnt_loss_val += 1\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY22hsSkln87"
      },
      "source": [
        "**Basic training loop**\r\n",
        "\r\n",
        "All together in one function that iterates through epochs and applies the previous learning/validation functions to the model respectively on training/validation sets. Here, we do not use any regularization technique, all params being set to None in the definition of the model. We want to see that the model overfits easily. And next, we'll refer to some regularization techniques, and optimise the set of hyperparameters they would suggest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HO9O-hs3d0a"
      },
      "source": [
        "def train_mnist(trial):\n",
        "\n",
        "  cfg = { 'n_epochs' : 60,\n",
        "          'seed' : 0,\n",
        "          'log_interval' : 50,\n",
        "          'lr' : 1e-3,          \n",
        "          'useL1': None, \n",
        "          'useL2': None, \n",
        "          'useBN': None, \n",
        "          'useDropout': None, \n",
        "          }\n",
        "\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  model = Net()\n",
        "  optimizer = optimizer = torch.optim.Adam(model.parameters(),lr=cfg['lr'])\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      train(cfg['log_interval'], model, train_loader, optimizer, criterion, epoch)\n",
        "      test_accuracy = test(model, val_loader, criterion)\n",
        "\n",
        "  return test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFcM2NzPaTSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90b9447-de7c-4e48-8bab-8612985f3866"
      },
      "source": [
        "writer = SummaryWriter(\"runs/\")\r\n",
        "sampler = optuna.samplers.TPESampler()\r\n",
        "study = optuna.create_study(sampler=sampler, direction='maximize')\r\n",
        "study.optimize(func=train_mnist, n_trials=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:06:52,209]\u001b[0m A new study created in memory with name: no-name-8d41ca10-5ff5-45e7-a43b-cf930c67554d\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 Loss: 2.302570\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6843/10000 (68%)\n",
            "Train Epoch: 2 Loss: 2.297976\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6420/10000 (64%)\n",
            "Train Epoch: 3 Loss: 2.283094\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5865/10000 (59%)\n",
            "Train Epoch: 4 Loss: 2.276287\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7194/10000 (72%)\n",
            "Train Epoch: 5 Loss: 2.274063\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7508/10000 (75%)\n",
            "Train Epoch: 6 Loss: 2.273400\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7505/10000 (75%)\n",
            "Train Epoch: 7 Loss: 2.273252\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7535/10000 (75%)\n",
            "Train Epoch: 8 Loss: 2.273107\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7576/10000 (76%)\n",
            "Train Epoch: 9 Loss: 2.273041\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7635/10000 (76%)\n",
            "Train Epoch: 10 Loss: 2.273009\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7679/10000 (77%)\n",
            "Train Epoch: 11 Loss: 2.273002\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7727/10000 (77%)\n",
            "Train Epoch: 12 Loss: 2.272990\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7759/10000 (78%)\n",
            "Train Epoch: 13 Loss: 2.272982\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7793/10000 (78%)\n",
            "Train Epoch: 14 Loss: 2.272972\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7837/10000 (78%)\n",
            "Train Epoch: 15 Loss: 2.272965\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7872/10000 (79%)\n",
            "Train Epoch: 16 Loss: 2.272955\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7909/10000 (79%)\n",
            "Train Epoch: 17 Loss: 2.272938\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7929/10000 (79%)\n",
            "Train Epoch: 18 Loss: 2.272925\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7939/10000 (79%)\n",
            "Train Epoch: 19 Loss: 2.272915\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7954/10000 (80%)\n",
            "Train Epoch: 20 Loss: 2.272906\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7977/10000 (80%)\n",
            "Train Epoch: 21 Loss: 2.272896\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7993/10000 (80%)\n",
            "Train Epoch: 22 Loss: 2.272888\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8009/10000 (80%)\n",
            "Train Epoch: 23 Loss: 2.272881\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8017/10000 (80%)\n",
            "Train Epoch: 24 Loss: 2.272875\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8034/10000 (80%)\n",
            "Train Epoch: 25 Loss: 2.272867\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8046/10000 (80%)\n",
            "Train Epoch: 26 Loss: 2.272862\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8062/10000 (81%)\n",
            "Train Epoch: 27 Loss: 2.272856\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8072/10000 (81%)\n",
            "Train Epoch: 28 Loss: 2.272851\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8079/10000 (81%)\n",
            "Train Epoch: 29 Loss: 2.272847\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8090/10000 (81%)\n",
            "Train Epoch: 30 Loss: 2.272841\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8104/10000 (81%)\n",
            "Train Epoch: 31 Loss: 2.272836\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8113/10000 (81%)\n",
            "Train Epoch: 32 Loss: 2.272831\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8124/10000 (81%)\n",
            "Train Epoch: 33 Loss: 2.272826\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8140/10000 (81%)\n",
            "Train Epoch: 34 Loss: 2.272821\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8145/10000 (81%)\n",
            "Train Epoch: 35 Loss: 2.272817\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8148/10000 (81%)\n",
            "Train Epoch: 36 Loss: 2.272814\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8149/10000 (81%)\n",
            "Train Epoch: 37 Loss: 2.272809\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8157/10000 (82%)\n",
            "Train Epoch: 38 Loss: 2.272804\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8161/10000 (82%)\n",
            "Train Epoch: 39 Loss: 2.272800\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8170/10000 (82%)\n",
            "Train Epoch: 40 Loss: 2.272797\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8172/10000 (82%)\n",
            "Train Epoch: 41 Loss: 2.272794\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8183/10000 (82%)\n",
            "Train Epoch: 42 Loss: 2.272792\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8186/10000 (82%)\n",
            "Train Epoch: 43 Loss: 2.272788\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8192/10000 (82%)\n",
            "Train Epoch: 44 Loss: 2.272786\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8199/10000 (82%)\n",
            "Train Epoch: 45 Loss: 2.272783\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8209/10000 (82%)\n",
            "Train Epoch: 46 Loss: 2.272780\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8208/10000 (82%)\n",
            "Train Epoch: 47 Loss: 2.272779\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8212/10000 (82%)\n",
            "Train Epoch: 48 Loss: 2.272777\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8219/10000 (82%)\n",
            "Train Epoch: 49 Loss: 2.272774\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8225/10000 (82%)\n",
            "Train Epoch: 50 Loss: 2.272771\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8229/10000 (82%)\n",
            "Train Epoch: 51 Loss: 2.272770\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8242/10000 (82%)\n",
            "Train Epoch: 52 Loss: 2.272768\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8246/10000 (82%)\n",
            "Train Epoch: 53 Loss: 2.272767\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8247/10000 (82%)\n",
            "Train Epoch: 54 Loss: 2.272765\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8253/10000 (83%)\n",
            "Train Epoch: 55 Loss: 2.272763\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8266/10000 (83%)\n",
            "Train Epoch: 56 Loss: 2.272761\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8261/10000 (83%)\n",
            "Train Epoch: 57 Loss: 2.272761\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8276/10000 (83%)\n",
            "Train Epoch: 58 Loss: 2.272760\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8273/10000 (83%)\n",
            "Train Epoch: 59 Loss: 2.272757\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8290/10000 (83%)\n",
            "Train Epoch: 60 Loss: 2.272756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:08:58,638]\u001b[0m Trial 0 finished with value: 82.8 and parameters: {}. Best is trial 0 with value: 82.8.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8280/10000 (83%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm7t3gfI-1GF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "5eed62c0-099e-4246-cce2-6cdc620aaf61"
      },
      "source": [
        "df = study.trials_dataframe()\n",
        "df.head(5)\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"14fa9709-82c1-4cc7-9cc2-45275daf0498\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"14fa9709-82c1-4cc7-9cc2-45275daf0498\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '14fa9709-82c1-4cc7-9cc2-45275daf0498',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0], \"y\": [82.8]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0], \"y\": [82.8]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('14fa9709-82c1-4cc7-9cc2-45275daf0498');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHdH48qRrb8q",
        "outputId": "012b3415-4243-433a-e808-eea61a80c3c3"
      },
      "source": [
        "study.best_trial"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenTrial(number=0, values=[82.8], datetime_start=datetime.datetime(2021, 2, 23, 21, 6, 52, 210076), datetime_complete=datetime.datetime(2021, 2, 23, 21, 8, 58, 638396), params={}, distributions={}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ancxf4C6ttaA"
      },
      "source": [
        "Now, we can check learning curves in tensorboard ..\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpP3g0kTrnnj"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "otf_vD-7tdzR",
        "outputId": "4dc16efc-07f0-4074-d92f-2a65fb2441bd"
      },
      "source": [
        "%tensorboard --logdir 'runs'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 748), started 0:11:03 ago. (Use '!kill 748' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_IXWfyqXrqJ7",
        "outputId": "49e35394-a55d-44e1-bff2-6cd9accac555"
      },
      "source": [
        "from tensorboard import notebook\r\n",
        "notebook.display(height=1000) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting TensorBoard with logdir runs (started 0:11:03 ago; port 6006, pid 748).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '1000');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnO4qDUGmHMH"
      },
      "source": [
        "The best accuracy is show in ` value` column above.\r\n",
        "\r\n",
        "**Using regularization, and fine tuning hyperparameters**\r\n",
        "\r\n",
        "We will try to search for the best hyperparameters using the 95%\r\n",
        "of the remaining train set as validation. You can try to combine different types of regularizations.\r\n",
        "\r\n",
        "- L1 regularization (Lasso) : will end up with sparse weights with (many zeros)\r\n",
        "\r\n",
        "- L2 regularization (Ridge) : will end up with small values of weights\r\n",
        "\r\n",
        "- Dropout regularization: During training‚ for each training example randomly turn-off the neurons of hidden units (with p, a hyperparam)‚ this also removes the connections‚ for different training examples, turn-off different units\r\n",
        "\r\n",
        "- BatchNorm: subtracting a measure of location and dividing by a measure of scale\r\n",
        "\r\n",
        "Those techniques involve new hyperameters in the final algorithm. Thos are :\r\n",
        "\r\n",
        "- The proba $p$ for dropout\r\n",
        "- reg params for L1/L2\r\n",
        "- $\\epsilon$ for batchNorm ..\r\n",
        "\r\n",
        "In the following cells, we will add those into consideration in the definition of the model, and we will use optuna to search for the best values for them, so that the accuracy obtained finally is better, and we avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls7qOcblilIQ"
      },
      "source": [
        "def train_mnist_optuned(trial):\r\n",
        "\r\n",
        "  cfg = { 'n_epochs' : 60,\r\n",
        "          'seed' : 0,\r\n",
        "          'log_interval' : 50,\r\n",
        "          'save_model' : False,\r\n",
        "          'lr' : 1e-3,          \r\n",
        "          'useL1': trial.suggest_uniform('useL1', 1e-3, 1.5),\r\n",
        "          'useL2': trial.suggest_uniform('useL2', 1e-3, 1.5),\r\n",
        "          'useBN': trial.suggest_uniform('useBN', 1e-6, 1e-4),\r\n",
        "          'useDropout': trial.suggest_uniform('useDropout', 0.01, 0.55),\r\n",
        "          }\r\n",
        "\r\n",
        "  torch.manual_seed(cfg['seed'])\r\n",
        "  model = Net(cfg['useDropout'], cfg['useBN'], cfg['useL1'], cfg['useL2'])\r\n",
        "  optimizer = optimizer = torch.optim.Adam(model.parameters(),lr=cfg['lr'])\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  \r\n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\r\n",
        "      train(cfg['log_interval'], model, train_loader, optimizer, criterion, epoch)\r\n",
        "      test_accuracy = test(model, val_loader, criterion)\r\n",
        "      print(test_accuracy)\r\n",
        "  if cfg['save_model']:\r\n",
        "      torch.save(model.state_dict(), \"mnist_cnn.pt\")\r\n",
        "\r\n",
        "  return test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx4ukhVAj4Sq",
        "outputId": "2eee7093-2045-4ccd-a939-d76bd68a4ed6"
      },
      "source": [
        "writer = SummaryWriter(\"runs_optuna/\")\r\n",
        "sampler = optuna.samplers.TPESampler()\r\n",
        "study = optuna.create_study(sampler=sampler, direction='maximize')\r\n",
        "study.optimize(func=train_mnist_optuned, n_trials=10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:08:59,288]\u001b[0m A new study created in memory with name: no-name-1569ea58-af79-472a-bfd9-c2671285af2e\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 Loss: 2.302338\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6932/10000 (69%)\n",
            "69.32\n",
            "Train Epoch: 2 Loss: 2.290055\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6431/10000 (64%)\n",
            "64.31\n",
            "Train Epoch: 3 Loss: 2.282984\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5828/10000 (58%)\n",
            "58.28\n",
            "Train Epoch: 4 Loss: 2.277974\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5233/10000 (52%)\n",
            "52.33\n",
            "Train Epoch: 5 Loss: 2.275911\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5925/10000 (59%)\n",
            "59.25\n",
            "Train Epoch: 6 Loss: 2.274642\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6326/10000 (63%)\n",
            "63.26\n",
            "Train Epoch: 7 Loss: 2.274062\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6385/10000 (64%)\n",
            "63.85\n",
            "Train Epoch: 8 Loss: 2.273649\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6451/10000 (65%)\n",
            "64.51\n",
            "Train Epoch: 9 Loss: 2.273745\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6391/10000 (64%)\n",
            "63.91\n",
            "Train Epoch: 10 Loss: 2.273628\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6405/10000 (64%)\n",
            "64.05\n",
            "Train Epoch: 11 Loss: 2.273569\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6626/10000 (66%)\n",
            "66.26\n",
            "Train Epoch: 12 Loss: 2.273423\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6625/10000 (66%)\n",
            "66.25\n",
            "Train Epoch: 13 Loss: 2.273390\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6660/10000 (67%)\n",
            "66.6\n",
            "Train Epoch: 14 Loss: 2.273353\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6647/10000 (66%)\n",
            "66.47\n",
            "Train Epoch: 15 Loss: 2.273316\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6745/10000 (67%)\n",
            "67.45\n",
            "Train Epoch: 16 Loss: 2.273237\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6846/10000 (68%)\n",
            "68.46\n",
            "Train Epoch: 17 Loss: 2.273278\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6890/10000 (69%)\n",
            "68.9\n",
            "Train Epoch: 18 Loss: 2.273284\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6979/10000 (70%)\n",
            "69.79\n",
            "Train Epoch: 19 Loss: 2.273246\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7063/10000 (71%)\n",
            "70.63\n",
            "Train Epoch: 20 Loss: 2.273308\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7085/10000 (71%)\n",
            "70.85\n",
            "Train Epoch: 21 Loss: 2.273341\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7139/10000 (71%)\n",
            "71.39\n",
            "Train Epoch: 22 Loss: 2.273224\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7233/10000 (72%)\n",
            "72.33\n",
            "Train Epoch: 23 Loss: 2.273255\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7223/10000 (72%)\n",
            "72.23\n",
            "Train Epoch: 24 Loss: 2.273215\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7407/10000 (74%)\n",
            "74.07\n",
            "Train Epoch: 25 Loss: 2.273212\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7467/10000 (75%)\n",
            "74.67\n",
            "Train Epoch: 26 Loss: 2.273173\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7497/10000 (75%)\n",
            "74.97\n",
            "Train Epoch: 27 Loss: 2.273178\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7613/10000 (76%)\n",
            "76.13\n",
            "Train Epoch: 28 Loss: 2.273177\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7599/10000 (76%)\n",
            "75.99\n",
            "Train Epoch: 29 Loss: 2.273090\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7602/10000 (76%)\n",
            "76.02\n",
            "Train Epoch: 30 Loss: 2.273072\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7626/10000 (76%)\n",
            "76.26\n",
            "Train Epoch: 31 Loss: 2.273156\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7652/10000 (77%)\n",
            "76.52\n",
            "Train Epoch: 32 Loss: 2.273051\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7751/10000 (78%)\n",
            "77.51\n",
            "Train Epoch: 33 Loss: 2.273135\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7788/10000 (78%)\n",
            "77.88\n",
            "Train Epoch: 34 Loss: 2.273042\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7713/10000 (77%)\n",
            "77.13\n",
            "Train Epoch: 35 Loss: 2.273013\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7772/10000 (78%)\n",
            "77.72\n",
            "Train Epoch: 36 Loss: 2.273147\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7740/10000 (77%)\n",
            "77.4\n",
            "Train Epoch: 37 Loss: 2.273021\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7822/10000 (78%)\n",
            "78.22\n",
            "Train Epoch: 38 Loss: 2.273062\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7839/10000 (78%)\n",
            "78.39\n",
            "Train Epoch: 39 Loss: 2.273002\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7919/10000 (79%)\n",
            "79.19\n",
            "Train Epoch: 40 Loss: 2.272969\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7938/10000 (79%)\n",
            "79.38\n",
            "Train Epoch: 41 Loss: 2.272953\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7926/10000 (79%)\n",
            "79.26\n",
            "Train Epoch: 42 Loss: 2.273016\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7986/10000 (80%)\n",
            "79.86\n",
            "Train Epoch: 43 Loss: 2.273041\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7942/10000 (79%)\n",
            "79.42\n",
            "Train Epoch: 44 Loss: 2.272967\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7957/10000 (80%)\n",
            "79.57\n",
            "Train Epoch: 45 Loss: 2.272978\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7985/10000 (80%)\n",
            "79.85\n",
            "Train Epoch: 46 Loss: 2.273005\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8007/10000 (80%)\n",
            "80.07\n",
            "Train Epoch: 47 Loss: 2.272945\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8055/10000 (81%)\n",
            "80.55\n",
            "Train Epoch: 48 Loss: 2.272965\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8080/10000 (81%)\n",
            "80.8\n",
            "Train Epoch: 49 Loss: 2.272938\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8059/10000 (81%)\n",
            "80.59\n",
            "Train Epoch: 50 Loss: 2.272922\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8065/10000 (81%)\n",
            "80.65\n",
            "Train Epoch: 51 Loss: 2.272927\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8067/10000 (81%)\n",
            "80.67\n",
            "Train Epoch: 52 Loss: 2.272958\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8143/10000 (81%)\n",
            "81.43\n",
            "Train Epoch: 53 Loss: 2.272935\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8149/10000 (81%)\n",
            "81.49\n",
            "Train Epoch: 54 Loss: 2.272904\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8173/10000 (82%)\n",
            "81.73\n",
            "Train Epoch: 55 Loss: 2.272878\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8153/10000 (82%)\n",
            "81.53\n",
            "Train Epoch: 56 Loss: 2.272929\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8166/10000 (82%)\n",
            "81.66\n",
            "Train Epoch: 57 Loss: 2.272935\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8158/10000 (82%)\n",
            "81.58\n",
            "Train Epoch: 58 Loss: 2.272897\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8193/10000 (82%)\n",
            "81.93\n",
            "Train Epoch: 59 Loss: 2.272914\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8221/10000 (82%)\n",
            "82.21\n",
            "Train Epoch: 60 Loss: 2.272888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:11:13,471]\u001b[0m Trial 0 finished with value: 82.21 and parameters: {'useL1': 1.3299979099384567, 'useL2': 1.2171163641616152, 'useBN': 8.793668416014829e-05, 'useDropout': 0.09885545807242042}. Best is trial 0 with value: 82.21.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8221/10000 (82%)\n",
            "82.21\n",
            "Train Epoch: 1 Loss: 2.302455\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5418/10000 (54%)\n",
            "54.18\n",
            "Train Epoch: 2 Loss: 2.294991\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5470/10000 (55%)\n",
            "54.7\n",
            "Train Epoch: 3 Loss: 2.287803\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5607/10000 (56%)\n",
            "56.07\n",
            "Train Epoch: 4 Loss: 2.284765\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5563/10000 (56%)\n",
            "55.63\n",
            "Train Epoch: 5 Loss: 2.279413\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5231/10000 (52%)\n",
            "52.31\n",
            "Train Epoch: 6 Loss: 2.277336\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5262/10000 (53%)\n",
            "52.62\n",
            "Train Epoch: 7 Loss: 2.276395\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5732/10000 (57%)\n",
            "57.32\n",
            "Train Epoch: 8 Loss: 2.274555\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6058/10000 (61%)\n",
            "60.58\n",
            "Train Epoch: 9 Loss: 2.273979\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6087/10000 (61%)\n",
            "60.87\n",
            "Train Epoch: 10 Loss: 2.274008\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6190/10000 (62%)\n",
            "61.9\n",
            "Train Epoch: 11 Loss: 2.273938\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6177/10000 (62%)\n",
            "61.77\n",
            "Train Epoch: 12 Loss: 2.273976\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6158/10000 (62%)\n",
            "61.58\n",
            "Train Epoch: 13 Loss: 2.273882\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6227/10000 (62%)\n",
            "62.27\n",
            "Train Epoch: 14 Loss: 2.273868\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6382/10000 (64%)\n",
            "63.82\n",
            "Train Epoch: 15 Loss: 2.273921\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6566/10000 (66%)\n",
            "65.66\n",
            "Train Epoch: 16 Loss: 2.273589\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6434/10000 (64%)\n",
            "64.34\n",
            "Train Epoch: 17 Loss: 2.273862\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6603/10000 (66%)\n",
            "66.03\n",
            "Train Epoch: 18 Loss: 2.273884\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6539/10000 (65%)\n",
            "65.39\n",
            "Train Epoch: 19 Loss: 2.273774\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6677/10000 (67%)\n",
            "66.77\n",
            "Train Epoch: 20 Loss: 2.273907\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6720/10000 (67%)\n",
            "67.2\n",
            "Train Epoch: 21 Loss: 2.273767\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6882/10000 (69%)\n",
            "68.82\n",
            "Train Epoch: 22 Loss: 2.273458\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6723/10000 (67%)\n",
            "67.23\n",
            "Train Epoch: 23 Loss: 2.273983\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6675/10000 (67%)\n",
            "66.75\n",
            "Train Epoch: 24 Loss: 2.273931\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6995/10000 (70%)\n",
            "69.95\n",
            "Train Epoch: 25 Loss: 2.273795\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6984/10000 (70%)\n",
            "69.84\n",
            "Train Epoch: 26 Loss: 2.273848\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6973/10000 (70%)\n",
            "69.73\n",
            "Train Epoch: 27 Loss: 2.273538\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7055/10000 (71%)\n",
            "70.55\n",
            "Train Epoch: 28 Loss: 2.273674\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7082/10000 (71%)\n",
            "70.82\n",
            "Train Epoch: 29 Loss: 2.273555\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6953/10000 (70%)\n",
            "69.53\n",
            "Train Epoch: 30 Loss: 2.273522\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7184/10000 (72%)\n",
            "71.84\n",
            "Train Epoch: 31 Loss: 2.273696\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7229/10000 (72%)\n",
            "72.29\n",
            "Train Epoch: 32 Loss: 2.273600\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7335/10000 (73%)\n",
            "73.35\n",
            "Train Epoch: 33 Loss: 2.273642\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7296/10000 (73%)\n",
            "72.96\n",
            "Train Epoch: 34 Loss: 2.273593\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7316/10000 (73%)\n",
            "73.16\n",
            "Train Epoch: 35 Loss: 2.273600\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7472/10000 (75%)\n",
            "74.72\n",
            "Train Epoch: 36 Loss: 2.273370\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7420/10000 (74%)\n",
            "74.2\n",
            "Train Epoch: 37 Loss: 2.273471\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7453/10000 (75%)\n",
            "74.53\n",
            "Train Epoch: 38 Loss: 2.273738\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7549/10000 (75%)\n",
            "75.49\n",
            "Train Epoch: 39 Loss: 2.273644\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7454/10000 (75%)\n",
            "74.54\n",
            "Train Epoch: 40 Loss: 2.273499\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7473/10000 (75%)\n",
            "74.73\n",
            "Train Epoch: 41 Loss: 2.273399\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7447/10000 (74%)\n",
            "74.47\n",
            "Train Epoch: 42 Loss: 2.273542\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7736/10000 (77%)\n",
            "77.36\n",
            "Train Epoch: 43 Loss: 2.273396\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7645/10000 (76%)\n",
            "76.45\n",
            "Train Epoch: 44 Loss: 2.273476\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7716/10000 (77%)\n",
            "77.16\n",
            "Train Epoch: 45 Loss: 2.273710\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7685/10000 (77%)\n",
            "76.85\n",
            "Train Epoch: 46 Loss: 2.273388\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7802/10000 (78%)\n",
            "78.02\n",
            "Train Epoch: 47 Loss: 2.273299\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7876/10000 (79%)\n",
            "78.76\n",
            "Train Epoch: 48 Loss: 2.273422\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7908/10000 (79%)\n",
            "79.08\n",
            "Train Epoch: 49 Loss: 2.273563\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7984/10000 (80%)\n",
            "79.84\n",
            "Train Epoch: 50 Loss: 2.273434\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7990/10000 (80%)\n",
            "79.9\n",
            "Train Epoch: 51 Loss: 2.273404\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7975/10000 (80%)\n",
            "79.75\n",
            "Train Epoch: 52 Loss: 2.273379\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8069/10000 (81%)\n",
            "80.69\n",
            "Train Epoch: 53 Loss: 2.273613\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8096/10000 (81%)\n",
            "80.96\n",
            "Train Epoch: 54 Loss: 2.273298\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8091/10000 (81%)\n",
            "80.91\n",
            "Train Epoch: 55 Loss: 2.273463\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8176/10000 (82%)\n",
            "81.76\n",
            "Train Epoch: 56 Loss: 2.273304\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8104/10000 (81%)\n",
            "81.04\n",
            "Train Epoch: 57 Loss: 2.273359\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8165/10000 (82%)\n",
            "81.65\n",
            "Train Epoch: 58 Loss: 2.273415\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8150/10000 (82%)\n",
            "81.5\n",
            "Train Epoch: 59 Loss: 2.273456\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8180/10000 (82%)\n",
            "81.8\n",
            "Train Epoch: 60 Loss: 2.273377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:13:29,217]\u001b[0m Trial 1 finished with value: 82.37 and parameters: {'useL1': 0.7884187681395458, 'useL2': 1.414916436850826, 'useBN': 5.332709397669999e-06, 'useDropout': 0.4047077278036265}. Best is trial 1 with value: 82.37.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8237/10000 (82%)\n",
            "82.37\n",
            "Train Epoch: 1 Loss: 2.302356\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6749/10000 (67%)\n",
            "67.49\n",
            "Train Epoch: 2 Loss: 2.291683\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6548/10000 (65%)\n",
            "65.48\n",
            "Train Epoch: 3 Loss: 2.284290\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5974/10000 (60%)\n",
            "59.74\n",
            "Train Epoch: 4 Loss: 2.278826\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5230/10000 (52%)\n",
            "52.3\n",
            "Train Epoch: 5 Loss: 2.276105\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5411/10000 (54%)\n",
            "54.11\n",
            "Train Epoch: 6 Loss: 2.275342\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6333/10000 (63%)\n",
            "63.33\n",
            "Train Epoch: 7 Loss: 2.274183\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6335/10000 (63%)\n",
            "63.35\n",
            "Train Epoch: 8 Loss: 2.273837\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6473/10000 (65%)\n",
            "64.73\n",
            "Train Epoch: 9 Loss: 2.273517\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6465/10000 (65%)\n",
            "64.65\n",
            "Train Epoch: 10 Loss: 2.273623\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6468/10000 (65%)\n",
            "64.68\n",
            "Train Epoch: 11 Loss: 2.273717\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6572/10000 (66%)\n",
            "65.72\n",
            "Train Epoch: 12 Loss: 2.273532\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6777/10000 (68%)\n",
            "67.77\n",
            "Train Epoch: 13 Loss: 2.273540\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6768/10000 (68%)\n",
            "67.68\n",
            "Train Epoch: 14 Loss: 2.273521\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6908/10000 (69%)\n",
            "69.08\n",
            "Train Epoch: 15 Loss: 2.273501\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7002/10000 (70%)\n",
            "70.02\n",
            "Train Epoch: 16 Loss: 2.273348\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7061/10000 (71%)\n",
            "70.61\n",
            "Train Epoch: 17 Loss: 2.273369\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7125/10000 (71%)\n",
            "71.25\n",
            "Train Epoch: 18 Loss: 2.273676\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7152/10000 (72%)\n",
            "71.52\n",
            "Train Epoch: 19 Loss: 2.273384\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7244/10000 (72%)\n",
            "72.44\n",
            "Train Epoch: 20 Loss: 2.273373\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7274/10000 (73%)\n",
            "72.74\n",
            "Train Epoch: 21 Loss: 2.273438\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7255/10000 (73%)\n",
            "72.55\n",
            "Train Epoch: 22 Loss: 2.273385\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7316/10000 (73%)\n",
            "73.16\n",
            "Train Epoch: 23 Loss: 2.273371\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7349/10000 (73%)\n",
            "73.49\n",
            "Train Epoch: 24 Loss: 2.273391\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7463/10000 (75%)\n",
            "74.63\n",
            "Train Epoch: 25 Loss: 2.273369\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7470/10000 (75%)\n",
            "74.7\n",
            "Train Epoch: 26 Loss: 2.273364\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7432/10000 (74%)\n",
            "74.32\n",
            "Train Epoch: 27 Loss: 2.273403\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7576/10000 (76%)\n",
            "75.76\n",
            "Train Epoch: 28 Loss: 2.273257\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7711/10000 (77%)\n",
            "77.11\n",
            "Train Epoch: 29 Loss: 2.273336\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7639/10000 (76%)\n",
            "76.39\n",
            "Train Epoch: 30 Loss: 2.273248\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7775/10000 (78%)\n",
            "77.75\n",
            "Train Epoch: 31 Loss: 2.273363\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7857/10000 (79%)\n",
            "78.57\n",
            "Train Epoch: 32 Loss: 2.273216\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7779/10000 (78%)\n",
            "77.79\n",
            "Train Epoch: 33 Loss: 2.273211\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7950/10000 (80%)\n",
            "79.5\n",
            "Train Epoch: 34 Loss: 2.273144\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7917/10000 (79%)\n",
            "79.17\n",
            "Train Epoch: 35 Loss: 2.273206\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7945/10000 (79%)\n",
            "79.45\n",
            "Train Epoch: 36 Loss: 2.273154\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7973/10000 (80%)\n",
            "79.73\n",
            "Train Epoch: 37 Loss: 2.273182\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8023/10000 (80%)\n",
            "80.23\n",
            "Train Epoch: 38 Loss: 2.273272\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8134/10000 (81%)\n",
            "81.34\n",
            "Train Epoch: 39 Loss: 2.273163\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8178/10000 (82%)\n",
            "81.78\n",
            "Train Epoch: 40 Loss: 2.273242\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8105/10000 (81%)\n",
            "81.05\n",
            "Train Epoch: 41 Loss: 2.273173\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8141/10000 (81%)\n",
            "81.41\n",
            "Train Epoch: 42 Loss: 2.273102\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8267/10000 (83%)\n",
            "82.67\n",
            "Train Epoch: 43 Loss: 2.273100\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8276/10000 (83%)\n",
            "82.76\n",
            "Train Epoch: 44 Loss: 2.273178\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8279/10000 (83%)\n",
            "82.79\n",
            "Train Epoch: 45 Loss: 2.273064\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8336/10000 (83%)\n",
            "83.36\n",
            "Train Epoch: 46 Loss: 2.273098\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8355/10000 (84%)\n",
            "83.55\n",
            "Train Epoch: 47 Loss: 2.273033\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8315/10000 (83%)\n",
            "83.15\n",
            "Train Epoch: 48 Loss: 2.273048\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8401/10000 (84%)\n",
            "84.01\n",
            "Train Epoch: 49 Loss: 2.273054\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8422/10000 (84%)\n",
            "84.22\n",
            "Train Epoch: 50 Loss: 2.273000\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8412/10000 (84%)\n",
            "84.12\n",
            "Train Epoch: 51 Loss: 2.273153\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8426/10000 (84%)\n",
            "84.26\n",
            "Train Epoch: 52 Loss: 2.273057\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8418/10000 (84%)\n",
            "84.18\n",
            "Train Epoch: 53 Loss: 2.273209\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8487/10000 (85%)\n",
            "84.87\n",
            "Train Epoch: 54 Loss: 2.272964\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8506/10000 (85%)\n",
            "85.06\n",
            "Train Epoch: 55 Loss: 2.273050\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8561/10000 (86%)\n",
            "85.61\n",
            "Train Epoch: 56 Loss: 2.273087\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8506/10000 (85%)\n",
            "85.06\n",
            "Train Epoch: 57 Loss: 2.273006\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8490/10000 (85%)\n",
            "84.9\n",
            "Train Epoch: 58 Loss: 2.272887\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8555/10000 (86%)\n",
            "85.55\n",
            "Train Epoch: 59 Loss: 2.272993\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8516/10000 (85%)\n",
            "85.16\n",
            "Train Epoch: 60 Loss: 2.272932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:15:44,984]\u001b[0m Trial 2 finished with value: 85.8 and parameters: {'useL1': 1.0954845697545692, 'useL2': 0.7319594457514821, 'useBN': 8.376489584144275e-05, 'useDropout': 0.1905706043379012}. Best is trial 2 with value: 85.8.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8580/10000 (86%)\n",
            "85.8\n",
            "Train Epoch: 1 Loss: 2.302399\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 7056/10000 (71%)\n",
            "70.56\n",
            "Train Epoch: 2 Loss: 2.289455\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6395/10000 (64%)\n",
            "63.95\n",
            "Train Epoch: 3 Loss: 2.281791\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5677/10000 (57%)\n",
            "56.77\n",
            "Train Epoch: 4 Loss: 2.277287\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5345/10000 (53%)\n",
            "53.45\n",
            "Train Epoch: 5 Loss: 2.275430\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6470/10000 (65%)\n",
            "64.7\n",
            "Train Epoch: 6 Loss: 2.273951\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6276/10000 (63%)\n",
            "62.76\n",
            "Train Epoch: 7 Loss: 2.273802\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6283/10000 (63%)\n",
            "62.83\n",
            "Train Epoch: 8 Loss: 2.273604\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6336/10000 (63%)\n",
            "63.36\n",
            "Train Epoch: 9 Loss: 2.273712\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6350/10000 (64%)\n",
            "63.5\n",
            "Train Epoch: 10 Loss: 2.273501\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6440/10000 (64%)\n",
            "64.4\n",
            "Train Epoch: 11 Loss: 2.273465\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6631/10000 (66%)\n",
            "66.31\n",
            "Train Epoch: 12 Loss: 2.273264\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6592/10000 (66%)\n",
            "65.92\n",
            "Train Epoch: 13 Loss: 2.273333\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6630/10000 (66%)\n",
            "66.3\n",
            "Train Epoch: 14 Loss: 2.273248\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6666/10000 (67%)\n",
            "66.66\n",
            "Train Epoch: 15 Loss: 2.273254\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6754/10000 (68%)\n",
            "67.54\n",
            "Train Epoch: 16 Loss: 2.273178\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6796/10000 (68%)\n",
            "67.96\n",
            "Train Epoch: 17 Loss: 2.273200\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6831/10000 (68%)\n",
            "68.31\n",
            "Train Epoch: 18 Loss: 2.273122\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6801/10000 (68%)\n",
            "68.01\n",
            "Train Epoch: 19 Loss: 2.273129\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6888/10000 (69%)\n",
            "68.88\n",
            "Train Epoch: 20 Loss: 2.273139\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6924/10000 (69%)\n",
            "69.24\n",
            "Train Epoch: 21 Loss: 2.273089\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6945/10000 (69%)\n",
            "69.45\n",
            "Train Epoch: 22 Loss: 2.273090\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6997/10000 (70%)\n",
            "69.97\n",
            "Train Epoch: 23 Loss: 2.273045\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6984/10000 (70%)\n",
            "69.84\n",
            "Train Epoch: 24 Loss: 2.273076\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7113/10000 (71%)\n",
            "71.13\n",
            "Train Epoch: 25 Loss: 2.273064\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7114/10000 (71%)\n",
            "71.14\n",
            "Train Epoch: 26 Loss: 2.273066\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7137/10000 (71%)\n",
            "71.37\n",
            "Train Epoch: 27 Loss: 2.273025\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7180/10000 (72%)\n",
            "71.8\n",
            "Train Epoch: 28 Loss: 2.273033\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7242/10000 (72%)\n",
            "72.42\n",
            "Train Epoch: 29 Loss: 2.273040\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7184/10000 (72%)\n",
            "71.84\n",
            "Train Epoch: 30 Loss: 2.273043\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7270/10000 (73%)\n",
            "72.7\n",
            "Train Epoch: 31 Loss: 2.273010\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7239/10000 (72%)\n",
            "72.39\n",
            "Train Epoch: 32 Loss: 2.272991\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7311/10000 (73%)\n",
            "73.11\n",
            "Train Epoch: 33 Loss: 2.273058\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7432/10000 (74%)\n",
            "74.32\n",
            "Train Epoch: 34 Loss: 2.272969\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7352/10000 (74%)\n",
            "73.52\n",
            "Train Epoch: 35 Loss: 2.272966\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7397/10000 (74%)\n",
            "73.97\n",
            "Train Epoch: 36 Loss: 2.273008\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7437/10000 (74%)\n",
            "74.37\n",
            "Train Epoch: 37 Loss: 2.272975\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7466/10000 (75%)\n",
            "74.66\n",
            "Train Epoch: 38 Loss: 2.272966\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7448/10000 (74%)\n",
            "74.48\n",
            "Train Epoch: 39 Loss: 2.272978\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7452/10000 (75%)\n",
            "74.52\n",
            "Train Epoch: 40 Loss: 2.272974\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7509/10000 (75%)\n",
            "75.09\n",
            "Train Epoch: 41 Loss: 2.272978\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7526/10000 (75%)\n",
            "75.26\n",
            "Train Epoch: 42 Loss: 2.272963\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7553/10000 (76%)\n",
            "75.53\n",
            "Train Epoch: 43 Loss: 2.272942\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7565/10000 (76%)\n",
            "75.65\n",
            "Train Epoch: 44 Loss: 2.272950\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7614/10000 (76%)\n",
            "76.14\n",
            "Train Epoch: 45 Loss: 2.273007\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7598/10000 (76%)\n",
            "75.98\n",
            "Train Epoch: 46 Loss: 2.272919\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7607/10000 (76%)\n",
            "76.07\n",
            "Train Epoch: 47 Loss: 2.272929\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7646/10000 (76%)\n",
            "76.46\n",
            "Train Epoch: 48 Loss: 2.272970\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7736/10000 (77%)\n",
            "77.36\n",
            "Train Epoch: 49 Loss: 2.272929\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7719/10000 (77%)\n",
            "77.19\n",
            "Train Epoch: 50 Loss: 2.272915\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7790/10000 (78%)\n",
            "77.9\n",
            "Train Epoch: 51 Loss: 2.272942\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7781/10000 (78%)\n",
            "77.81\n",
            "Train Epoch: 52 Loss: 2.272906\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7824/10000 (78%)\n",
            "78.24\n",
            "Train Epoch: 53 Loss: 2.272921\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7845/10000 (78%)\n",
            "78.45\n",
            "Train Epoch: 54 Loss: 2.272897\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7818/10000 (78%)\n",
            "78.18\n",
            "Train Epoch: 55 Loss: 2.272893\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7845/10000 (78%)\n",
            "78.45\n",
            "Train Epoch: 56 Loss: 2.272891\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7807/10000 (78%)\n",
            "78.07\n",
            "Train Epoch: 57 Loss: 2.272912\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7845/10000 (78%)\n",
            "78.45\n",
            "Train Epoch: 58 Loss: 2.272890\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7889/10000 (79%)\n",
            "78.89\n",
            "Train Epoch: 59 Loss: 2.272891\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7913/10000 (79%)\n",
            "79.13\n",
            "Train Epoch: 60 Loss: 2.272862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:18:00,880]\u001b[0m Trial 3 finished with value: 79.0 and parameters: {'useL1': 0.49997322857943116, 'useL2': 1.2458204131995336, 'useBN': 5.245638752026432e-05, 'useDropout': 0.03903115994955283}. Best is trial 2 with value: 85.8.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7900/10000 (79%)\n",
            "79.0\n",
            "Train Epoch: 1 Loss: 2.302373\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6045/10000 (60%)\n",
            "60.45\n",
            "Train Epoch: 2 Loss: 2.293587\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5973/10000 (60%)\n",
            "59.73\n",
            "Train Epoch: 3 Loss: 2.286195\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5795/10000 (58%)\n",
            "57.95\n",
            "Train Epoch: 4 Loss: 2.282235\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5682/10000 (57%)\n",
            "56.82\n",
            "Train Epoch: 5 Loss: 2.278370\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5369/10000 (54%)\n",
            "53.69\n",
            "Train Epoch: 6 Loss: 2.276321\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5659/10000 (57%)\n",
            "56.59\n",
            "Train Epoch: 7 Loss: 2.275139\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6255/10000 (63%)\n",
            "62.55\n",
            "Train Epoch: 8 Loss: 2.274055\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6319/10000 (63%)\n",
            "63.19\n",
            "Train Epoch: 9 Loss: 2.273958\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6240/10000 (62%)\n",
            "62.4\n",
            "Train Epoch: 10 Loss: 2.273910\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6200/10000 (62%)\n",
            "62.0\n",
            "Train Epoch: 11 Loss: 2.274009\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6486/10000 (65%)\n",
            "64.86\n",
            "Train Epoch: 12 Loss: 2.273691\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6341/10000 (63%)\n",
            "63.41\n",
            "Train Epoch: 13 Loss: 2.273720\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6394/10000 (64%)\n",
            "63.94\n",
            "Train Epoch: 14 Loss: 2.273746\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6639/10000 (66%)\n",
            "66.39\n",
            "Train Epoch: 15 Loss: 2.273798\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6678/10000 (67%)\n",
            "66.78\n",
            "Train Epoch: 16 Loss: 2.273702\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6599/10000 (66%)\n",
            "65.99\n",
            "Train Epoch: 17 Loss: 2.273769\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6597/10000 (66%)\n",
            "65.97\n",
            "Train Epoch: 18 Loss: 2.273924\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6765/10000 (68%)\n",
            "67.65\n",
            "Train Epoch: 19 Loss: 2.273594\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6870/10000 (69%)\n",
            "68.7\n",
            "Train Epoch: 20 Loss: 2.273662\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6844/10000 (68%)\n",
            "68.44\n",
            "Train Epoch: 21 Loss: 2.273599\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7082/10000 (71%)\n",
            "70.82\n",
            "Train Epoch: 22 Loss: 2.273487\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7093/10000 (71%)\n",
            "70.93\n",
            "Train Epoch: 23 Loss: 2.273593\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6950/10000 (70%)\n",
            "69.5\n",
            "Train Epoch: 24 Loss: 2.273834\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7098/10000 (71%)\n",
            "70.98\n",
            "Train Epoch: 25 Loss: 2.273337\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7209/10000 (72%)\n",
            "72.09\n",
            "Train Epoch: 26 Loss: 2.273381\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7227/10000 (72%)\n",
            "72.27\n",
            "Train Epoch: 27 Loss: 2.273443\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7318/10000 (73%)\n",
            "73.18\n",
            "Train Epoch: 28 Loss: 2.273434\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7569/10000 (76%)\n",
            "75.69\n",
            "Train Epoch: 29 Loss: 2.273269\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7452/10000 (75%)\n",
            "74.52\n",
            "Train Epoch: 30 Loss: 2.273383\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7476/10000 (75%)\n",
            "74.76\n",
            "Train Epoch: 31 Loss: 2.273487\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7552/10000 (76%)\n",
            "75.52\n",
            "Train Epoch: 32 Loss: 2.273415\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7599/10000 (76%)\n",
            "75.99\n",
            "Train Epoch: 33 Loss: 2.273375\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7714/10000 (77%)\n",
            "77.14\n",
            "Train Epoch: 34 Loss: 2.273465\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7715/10000 (77%)\n",
            "77.15\n",
            "Train Epoch: 35 Loss: 2.273396\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7810/10000 (78%)\n",
            "78.1\n",
            "Train Epoch: 36 Loss: 2.273306\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7811/10000 (78%)\n",
            "78.11\n",
            "Train Epoch: 37 Loss: 2.273348\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7891/10000 (79%)\n",
            "78.91\n",
            "Train Epoch: 38 Loss: 2.273718\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7978/10000 (80%)\n",
            "79.78\n",
            "Train Epoch: 39 Loss: 2.273520\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8058/10000 (81%)\n",
            "80.58\n",
            "Train Epoch: 40 Loss: 2.273335\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8040/10000 (80%)\n",
            "80.4\n",
            "Train Epoch: 41 Loss: 2.273245\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7990/10000 (80%)\n",
            "79.9\n",
            "Train Epoch: 42 Loss: 2.273307\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8104/10000 (81%)\n",
            "81.04\n",
            "Train Epoch: 43 Loss: 2.273366\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8149/10000 (81%)\n",
            "81.49\n",
            "Train Epoch: 44 Loss: 2.273298\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8213/10000 (82%)\n",
            "82.13\n",
            "Train Epoch: 45 Loss: 2.273473\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8142/10000 (81%)\n",
            "81.42\n",
            "Train Epoch: 46 Loss: 2.273455\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8204/10000 (82%)\n",
            "82.04\n",
            "Train Epoch: 47 Loss: 2.273304\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8273/10000 (83%)\n",
            "82.73\n",
            "Train Epoch: 48 Loss: 2.273356\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8338/10000 (83%)\n",
            "83.38\n",
            "Train Epoch: 49 Loss: 2.273211\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8365/10000 (84%)\n",
            "83.65\n",
            "Train Epoch: 50 Loss: 2.273327\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8382/10000 (84%)\n",
            "83.82\n",
            "Train Epoch: 51 Loss: 2.273228\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8320/10000 (83%)\n",
            "83.2\n",
            "Train Epoch: 52 Loss: 2.273420\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8384/10000 (84%)\n",
            "83.84\n",
            "Train Epoch: 53 Loss: 2.273215\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8454/10000 (85%)\n",
            "84.54\n",
            "Train Epoch: 54 Loss: 2.273094\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8486/10000 (85%)\n",
            "84.86\n",
            "Train Epoch: 55 Loss: 2.273281\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8493/10000 (85%)\n",
            "84.93\n",
            "Train Epoch: 56 Loss: 2.273073\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8504/10000 (85%)\n",
            "85.04\n",
            "Train Epoch: 57 Loss: 2.273058\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8500/10000 (85%)\n",
            "85.0\n",
            "Train Epoch: 58 Loss: 2.272975\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8535/10000 (85%)\n",
            "85.35\n",
            "Train Epoch: 59 Loss: 2.273118\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8542/10000 (85%)\n",
            "85.42\n",
            "Train Epoch: 60 Loss: 2.273026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:20:16,889]\u001b[0m Trial 4 finished with value: 85.53 and parameters: {'useL1': 1.445213304579667, 'useL2': 0.20290042232917543, 'useBN': 2.8811004858937098e-05, 'useDropout': 0.30324713649000123}. Best is trial 2 with value: 85.8.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8553/10000 (86%)\n",
            "85.53\n",
            "Train Epoch: 1 Loss: 2.302396\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6052/10000 (61%)\n",
            "60.52\n",
            "Train Epoch: 2 Loss: 2.293695\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5924/10000 (59%)\n",
            "59.24\n",
            "Train Epoch: 3 Loss: 2.286338\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5802/10000 (58%)\n",
            "58.02\n",
            "Train Epoch: 4 Loss: 2.282177\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5674/10000 (57%)\n",
            "56.74\n",
            "Train Epoch: 5 Loss: 2.277806\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5252/10000 (53%)\n",
            "52.52\n",
            "Train Epoch: 6 Loss: 2.276273\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5615/10000 (56%)\n",
            "56.15\n",
            "Train Epoch: 7 Loss: 2.275402\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6199/10000 (62%)\n",
            "61.99\n",
            "Train Epoch: 8 Loss: 2.274058\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6286/10000 (63%)\n",
            "62.86\n",
            "Train Epoch: 9 Loss: 2.274046\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6206/10000 (62%)\n",
            "62.06\n",
            "Train Epoch: 10 Loss: 2.273834\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6175/10000 (62%)\n",
            "61.75\n",
            "Train Epoch: 11 Loss: 2.273830\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6463/10000 (65%)\n",
            "64.63\n",
            "Train Epoch: 12 Loss: 2.273728\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6362/10000 (64%)\n",
            "63.62\n",
            "Train Epoch: 13 Loss: 2.273727\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6426/10000 (64%)\n",
            "64.26\n",
            "Train Epoch: 14 Loss: 2.273815\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6729/10000 (67%)\n",
            "67.29\n",
            "Train Epoch: 15 Loss: 2.273747\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6697/10000 (67%)\n",
            "66.97\n",
            "Train Epoch: 16 Loss: 2.273504\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6593/10000 (66%)\n",
            "65.93\n",
            "Train Epoch: 17 Loss: 2.273846\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6772/10000 (68%)\n",
            "67.72\n",
            "Train Epoch: 18 Loss: 2.273650\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6781/10000 (68%)\n",
            "67.81\n",
            "Train Epoch: 19 Loss: 2.273713\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6905/10000 (69%)\n",
            "69.05\n",
            "Train Epoch: 20 Loss: 2.273581\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6866/10000 (69%)\n",
            "68.66\n",
            "Train Epoch: 21 Loss: 2.273618\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7132/10000 (71%)\n",
            "71.32\n",
            "Train Epoch: 22 Loss: 2.273549\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7028/10000 (70%)\n",
            "70.28\n",
            "Train Epoch: 23 Loss: 2.273604\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7034/10000 (70%)\n",
            "70.34\n",
            "Train Epoch: 24 Loss: 2.273811\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7019/10000 (70%)\n",
            "70.19\n",
            "Train Epoch: 25 Loss: 2.273480\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7212/10000 (72%)\n",
            "72.12\n",
            "Train Epoch: 26 Loss: 2.273406\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7181/10000 (72%)\n",
            "71.81\n",
            "Train Epoch: 27 Loss: 2.273529\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7202/10000 (72%)\n",
            "72.02\n",
            "Train Epoch: 28 Loss: 2.273480\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7338/10000 (73%)\n",
            "73.38\n",
            "Train Epoch: 29 Loss: 2.273290\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7408/10000 (74%)\n",
            "74.08\n",
            "Train Epoch: 30 Loss: 2.273392\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7400/10000 (74%)\n",
            "74.0\n",
            "Train Epoch: 31 Loss: 2.273390\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7539/10000 (75%)\n",
            "75.39\n",
            "Train Epoch: 32 Loss: 2.273413\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7577/10000 (76%)\n",
            "75.77\n",
            "Train Epoch: 33 Loss: 2.273503\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7733/10000 (77%)\n",
            "77.33\n",
            "Train Epoch: 34 Loss: 2.273319\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7667/10000 (77%)\n",
            "76.67\n",
            "Train Epoch: 35 Loss: 2.273386\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7862/10000 (79%)\n",
            "78.62\n",
            "Train Epoch: 36 Loss: 2.273380\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7750/10000 (78%)\n",
            "77.5\n",
            "Train Epoch: 37 Loss: 2.273322\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7815/10000 (78%)\n",
            "78.15\n",
            "Train Epoch: 38 Loss: 2.273618\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7911/10000 (79%)\n",
            "79.11\n",
            "Train Epoch: 39 Loss: 2.273535\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7966/10000 (80%)\n",
            "79.66\n",
            "Train Epoch: 40 Loss: 2.273326\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7896/10000 (79%)\n",
            "78.96\n",
            "Train Epoch: 41 Loss: 2.273206\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7893/10000 (79%)\n",
            "78.93\n",
            "Train Epoch: 42 Loss: 2.273317\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8043/10000 (80%)\n",
            "80.43\n",
            "Train Epoch: 43 Loss: 2.273245\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8064/10000 (81%)\n",
            "80.64\n",
            "Train Epoch: 44 Loss: 2.273326\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8131/10000 (81%)\n",
            "81.31\n",
            "Train Epoch: 45 Loss: 2.273479\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8101/10000 (81%)\n",
            "81.01\n",
            "Train Epoch: 46 Loss: 2.273166\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8214/10000 (82%)\n",
            "82.14\n",
            "Train Epoch: 47 Loss: 2.273135\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8176/10000 (82%)\n",
            "81.76\n",
            "Train Epoch: 48 Loss: 2.273286\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8280/10000 (83%)\n",
            "82.8\n",
            "Train Epoch: 49 Loss: 2.273237\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8235/10000 (82%)\n",
            "82.35\n",
            "Train Epoch: 50 Loss: 2.273322\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8306/10000 (83%)\n",
            "83.06\n",
            "Train Epoch: 51 Loss: 2.273334\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8212/10000 (82%)\n",
            "82.12\n",
            "Train Epoch: 52 Loss: 2.273153\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8280/10000 (83%)\n",
            "82.8\n",
            "Train Epoch: 53 Loss: 2.273352\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8362/10000 (84%)\n",
            "83.62\n",
            "Train Epoch: 54 Loss: 2.273266\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8388/10000 (84%)\n",
            "83.88\n",
            "Train Epoch: 55 Loss: 2.273301\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8441/10000 (84%)\n",
            "84.41\n",
            "Train Epoch: 56 Loss: 2.273166\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8426/10000 (84%)\n",
            "84.26\n",
            "Train Epoch: 57 Loss: 2.273051\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8429/10000 (84%)\n",
            "84.29\n",
            "Train Epoch: 58 Loss: 2.273054\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8455/10000 (85%)\n",
            "84.55\n",
            "Train Epoch: 59 Loss: 2.273064\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8498/10000 (85%)\n",
            "84.98\n",
            "Train Epoch: 60 Loss: 2.273046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:22:32,996]\u001b[0m Trial 5 finished with value: 85.0 and parameters: {'useL1': 1.0915451311091195, 'useL2': 0.656132167917855, 'useBN': 4.944518662634461e-05, 'useDropout': 0.31883186013787307}. Best is trial 2 with value: 85.8.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8500/10000 (85%)\n",
            "85.0\n",
            "Train Epoch: 1 Loss: 2.302483\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5020/10000 (50%)\n",
            "50.2\n",
            "Train Epoch: 2 Loss: 2.295223\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5327/10000 (53%)\n",
            "53.27\n",
            "Train Epoch: 3 Loss: 2.288407\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5430/10000 (54%)\n",
            "54.3\n",
            "Train Epoch: 4 Loss: 2.285362\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5380/10000 (54%)\n",
            "53.8\n",
            "Train Epoch: 5 Loss: 2.280049\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5146/10000 (51%)\n",
            "51.46\n",
            "Train Epoch: 6 Loss: 2.277508\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 4988/10000 (50%)\n",
            "49.88\n",
            "Train Epoch: 7 Loss: 2.276504\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5408/10000 (54%)\n",
            "54.08\n",
            "Train Epoch: 8 Loss: 2.274813\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5792/10000 (58%)\n",
            "57.92\n",
            "Train Epoch: 9 Loss: 2.274299\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5857/10000 (59%)\n",
            "58.57\n",
            "Train Epoch: 10 Loss: 2.273946\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5842/10000 (58%)\n",
            "58.42\n",
            "Train Epoch: 11 Loss: 2.274240\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5763/10000 (58%)\n",
            "57.63\n",
            "Train Epoch: 12 Loss: 2.274199\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5801/10000 (58%)\n",
            "58.01\n",
            "Train Epoch: 13 Loss: 2.273864\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5785/10000 (58%)\n",
            "57.85\n",
            "Train Epoch: 14 Loss: 2.273957\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5913/10000 (59%)\n",
            "59.13\n",
            "Train Epoch: 15 Loss: 2.274062\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6065/10000 (61%)\n",
            "60.65\n",
            "Train Epoch: 16 Loss: 2.273739\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5946/10000 (59%)\n",
            "59.46\n",
            "Train Epoch: 17 Loss: 2.273643\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6026/10000 (60%)\n",
            "60.26\n",
            "Train Epoch: 18 Loss: 2.274073\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6125/10000 (61%)\n",
            "61.25\n",
            "Train Epoch: 19 Loss: 2.273857\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6204/10000 (62%)\n",
            "62.04\n",
            "Train Epoch: 20 Loss: 2.273791\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6312/10000 (63%)\n",
            "63.12\n",
            "Train Epoch: 21 Loss: 2.273932\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6450/10000 (64%)\n",
            "64.5\n",
            "Train Epoch: 22 Loss: 2.273753\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6434/10000 (64%)\n",
            "64.34\n",
            "Train Epoch: 23 Loss: 2.273782\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6317/10000 (63%)\n",
            "63.17\n",
            "Train Epoch: 24 Loss: 2.273745\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6478/10000 (65%)\n",
            "64.78\n",
            "Train Epoch: 25 Loss: 2.273728\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6541/10000 (65%)\n",
            "65.41\n",
            "Train Epoch: 26 Loss: 2.273625\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6467/10000 (65%)\n",
            "64.67\n",
            "Train Epoch: 27 Loss: 2.273812\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6555/10000 (66%)\n",
            "65.55\n",
            "Train Epoch: 28 Loss: 2.273618\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6731/10000 (67%)\n",
            "67.31\n",
            "Train Epoch: 29 Loss: 2.273589\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6635/10000 (66%)\n",
            "66.35\n",
            "Train Epoch: 30 Loss: 2.273433\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6763/10000 (68%)\n",
            "67.63\n",
            "Train Epoch: 31 Loss: 2.273644\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6765/10000 (68%)\n",
            "67.65\n",
            "Train Epoch: 32 Loss: 2.273542\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6847/10000 (68%)\n",
            "68.47\n",
            "Train Epoch: 33 Loss: 2.273737\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6818/10000 (68%)\n",
            "68.18\n",
            "Train Epoch: 34 Loss: 2.273827\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6794/10000 (68%)\n",
            "67.94\n",
            "Train Epoch: 35 Loss: 2.273439\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6961/10000 (70%)\n",
            "69.61\n",
            "Train Epoch: 36 Loss: 2.273472\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6905/10000 (69%)\n",
            "69.05\n",
            "Train Epoch: 37 Loss: 2.273607\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6912/10000 (69%)\n",
            "69.12\n",
            "Train Epoch: 38 Loss: 2.273820\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6912/10000 (69%)\n",
            "69.12\n",
            "Train Epoch: 39 Loss: 2.274044\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6964/10000 (70%)\n",
            "69.64\n",
            "Train Epoch: 40 Loss: 2.273624\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7119/10000 (71%)\n",
            "71.19\n",
            "Train Epoch: 41 Loss: 2.273572\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7148/10000 (71%)\n",
            "71.48\n",
            "Train Epoch: 42 Loss: 2.273617\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7341/10000 (73%)\n",
            "73.41\n",
            "Train Epoch: 43 Loss: 2.273536\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7232/10000 (72%)\n",
            "72.32\n",
            "Train Epoch: 44 Loss: 2.273588\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7353/10000 (74%)\n",
            "73.53\n",
            "Train Epoch: 45 Loss: 2.273716\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7363/10000 (74%)\n",
            "73.63\n",
            "Train Epoch: 46 Loss: 2.273403\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7409/10000 (74%)\n",
            "74.09\n",
            "Train Epoch: 47 Loss: 2.273564\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7450/10000 (74%)\n",
            "74.5\n",
            "Train Epoch: 48 Loss: 2.273560\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7448/10000 (74%)\n",
            "74.48\n",
            "Train Epoch: 49 Loss: 2.273636\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7541/10000 (75%)\n",
            "75.41\n",
            "Train Epoch: 50 Loss: 2.273429\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7542/10000 (75%)\n",
            "75.42\n",
            "Train Epoch: 51 Loss: 2.273589\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7591/10000 (76%)\n",
            "75.91\n",
            "Train Epoch: 52 Loss: 2.273281\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7690/10000 (77%)\n",
            "76.9\n",
            "Train Epoch: 53 Loss: 2.273580\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7696/10000 (77%)\n",
            "76.96\n",
            "Train Epoch: 54 Loss: 2.273638\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7782/10000 (78%)\n",
            "77.82\n",
            "Train Epoch: 55 Loss: 2.273531\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7720/10000 (77%)\n",
            "77.2\n",
            "Train Epoch: 56 Loss: 2.273566\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7809/10000 (78%)\n",
            "78.09\n",
            "Train Epoch: 57 Loss: 2.273351\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7803/10000 (78%)\n",
            "78.03\n",
            "Train Epoch: 58 Loss: 2.273388\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7727/10000 (77%)\n",
            "77.27\n",
            "Train Epoch: 59 Loss: 2.273391\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7783/10000 (78%)\n",
            "77.83\n",
            "Train Epoch: 60 Loss: 2.273327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:24:49,061]\u001b[0m Trial 6 finished with value: 79.58 and parameters: {'useL1': 0.7043677929346749, 'useL2': 1.4058901137639848, 'useBN': 9.832279247522227e-05, 'useDropout': 0.4481277117848583}. Best is trial 2 with value: 85.8.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7958/10000 (80%)\n",
            "79.58\n",
            "Train Epoch: 1 Loss: 2.302445\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5394/10000 (54%)\n",
            "53.94\n",
            "Train Epoch: 2 Loss: 2.295125\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5478/10000 (55%)\n",
            "54.78\n",
            "Train Epoch: 3 Loss: 2.287757\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5570/10000 (56%)\n",
            "55.7\n",
            "Train Epoch: 4 Loss: 2.284721\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 5560/10000 (56%)\n",
            "55.6\n",
            "Train Epoch: 5 Loss: 2.279564\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5232/10000 (52%)\n",
            "52.32\n",
            "Train Epoch: 6 Loss: 2.277420\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5317/10000 (53%)\n",
            "53.17\n",
            "Train Epoch: 7 Loss: 2.276284\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5775/10000 (58%)\n",
            "57.75\n",
            "Train Epoch: 8 Loss: 2.274524\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6047/10000 (60%)\n",
            "60.47\n",
            "Train Epoch: 9 Loss: 2.273998\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6094/10000 (61%)\n",
            "60.94\n",
            "Train Epoch: 10 Loss: 2.273950\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6192/10000 (62%)\n",
            "61.92\n",
            "Train Epoch: 11 Loss: 2.273926\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6148/10000 (61%)\n",
            "61.48\n",
            "Train Epoch: 12 Loss: 2.273973\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6058/10000 (61%)\n",
            "60.58\n",
            "Train Epoch: 13 Loss: 2.273909\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6112/10000 (61%)\n",
            "61.12\n",
            "Train Epoch: 14 Loss: 2.273845\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6271/10000 (63%)\n",
            "62.71\n",
            "Train Epoch: 15 Loss: 2.273989\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6469/10000 (65%)\n",
            "64.69\n",
            "Train Epoch: 16 Loss: 2.273612\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6362/10000 (64%)\n",
            "63.62\n",
            "Train Epoch: 17 Loss: 2.273952\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6526/10000 (65%)\n",
            "65.26\n",
            "Train Epoch: 18 Loss: 2.273889\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6535/10000 (65%)\n",
            "65.35\n",
            "Train Epoch: 19 Loss: 2.273762\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6586/10000 (66%)\n",
            "65.86\n",
            "Train Epoch: 20 Loss: 2.273836\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6590/10000 (66%)\n",
            "65.9\n",
            "Train Epoch: 21 Loss: 2.273945\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6795/10000 (68%)\n",
            "67.95\n",
            "Train Epoch: 22 Loss: 2.273508\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6730/10000 (67%)\n",
            "67.3\n",
            "Train Epoch: 23 Loss: 2.273950\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6715/10000 (67%)\n",
            "67.15\n",
            "Train Epoch: 24 Loss: 2.274042\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6896/10000 (69%)\n",
            "68.96\n",
            "Train Epoch: 25 Loss: 2.273715\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6888/10000 (69%)\n",
            "68.88\n",
            "Train Epoch: 26 Loss: 2.273832\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6988/10000 (70%)\n",
            "69.88\n",
            "Train Epoch: 27 Loss: 2.273542\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6957/10000 (70%)\n",
            "69.57\n",
            "Train Epoch: 28 Loss: 2.273669\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6995/10000 (70%)\n",
            "69.95\n",
            "Train Epoch: 29 Loss: 2.273679\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6928/10000 (69%)\n",
            "69.28\n",
            "Train Epoch: 30 Loss: 2.273809\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7046/10000 (70%)\n",
            "70.46\n",
            "Train Epoch: 31 Loss: 2.273662\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7138/10000 (71%)\n",
            "71.38\n",
            "Train Epoch: 32 Loss: 2.273526\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7239/10000 (72%)\n",
            "72.39\n",
            "Train Epoch: 33 Loss: 2.273657\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7270/10000 (73%)\n",
            "72.7\n",
            "Train Epoch: 34 Loss: 2.273678\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7201/10000 (72%)\n",
            "72.01\n",
            "Train Epoch: 35 Loss: 2.273530\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7385/10000 (74%)\n",
            "73.85\n",
            "Train Epoch: 36 Loss: 2.273360\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7370/10000 (74%)\n",
            "73.7\n",
            "Train Epoch: 37 Loss: 2.273431\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7383/10000 (74%)\n",
            "73.83\n",
            "Train Epoch: 38 Loss: 2.273645\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7449/10000 (74%)\n",
            "74.49\n",
            "Train Epoch: 39 Loss: 2.273594\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7401/10000 (74%)\n",
            "74.01\n",
            "Train Epoch: 40 Loss: 2.273541\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7458/10000 (75%)\n",
            "74.58\n",
            "Train Epoch: 41 Loss: 2.273269\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7404/10000 (74%)\n",
            "74.04\n",
            "Train Epoch: 42 Loss: 2.273594\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7598/10000 (76%)\n",
            "75.98\n",
            "Train Epoch: 43 Loss: 2.273483\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7592/10000 (76%)\n",
            "75.92\n",
            "Train Epoch: 44 Loss: 2.273614\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7555/10000 (76%)\n",
            "75.55\n",
            "Train Epoch: 45 Loss: 2.273700\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7622/10000 (76%)\n",
            "76.22\n",
            "Train Epoch: 46 Loss: 2.273287\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7736/10000 (77%)\n",
            "77.36\n",
            "Train Epoch: 47 Loss: 2.273361\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7753/10000 (78%)\n",
            "77.53\n",
            "Train Epoch: 48 Loss: 2.273519\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7832/10000 (78%)\n",
            "78.32\n",
            "Train Epoch: 49 Loss: 2.273326\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7938/10000 (79%)\n",
            "79.38\n",
            "Train Epoch: 50 Loss: 2.273616\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8004/10000 (80%)\n",
            "80.04\n",
            "Train Epoch: 51 Loss: 2.273397\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7867/10000 (79%)\n",
            "78.67\n",
            "Train Epoch: 52 Loss: 2.273325\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8011/10000 (80%)\n",
            "80.11\n",
            "Train Epoch: 53 Loss: 2.273745\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8062/10000 (81%)\n",
            "80.62\n",
            "Train Epoch: 54 Loss: 2.273430\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8088/10000 (81%)\n",
            "80.88\n",
            "Train Epoch: 55 Loss: 2.273378\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8106/10000 (81%)\n",
            "81.06\n",
            "Train Epoch: 56 Loss: 2.273195\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8009/10000 (80%)\n",
            "80.09\n",
            "Train Epoch: 57 Loss: 2.273309\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8118/10000 (81%)\n",
            "81.18\n",
            "Train Epoch: 58 Loss: 2.273276\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8080/10000 (81%)\n",
            "80.8\n",
            "Train Epoch: 59 Loss: 2.273430\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8120/10000 (81%)\n",
            "81.2\n",
            "Train Epoch: 60 Loss: 2.273304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:27:05,247]\u001b[0m Trial 7 finished with value: 81.51 and parameters: {'useL1': 1.4687190611794578, 'useL2': 0.8719185738624136, 'useBN': 3.782153898763246e-05, 'useDropout': 0.40604501524697706}. Best is trial 2 with value: 85.8.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8151/10000 (82%)\n",
            "81.51\n",
            "Train Epoch: 1 Loss: 2.302352\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6454/10000 (65%)\n",
            "64.54\n",
            "Train Epoch: 2 Loss: 2.292426\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6204/10000 (62%)\n",
            "62.04\n",
            "Train Epoch: 3 Loss: 2.285414\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6030/10000 (60%)\n",
            "60.3\n",
            "Train Epoch: 4 Loss: 2.281284\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5637/10000 (56%)\n",
            "56.37\n",
            "Train Epoch: 5 Loss: 2.276997\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5574/10000 (56%)\n",
            "55.74\n",
            "Train Epoch: 6 Loss: 2.275547\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6260/10000 (63%)\n",
            "62.6\n",
            "Train Epoch: 7 Loss: 2.274502\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6247/10000 (62%)\n",
            "62.47\n",
            "Train Epoch: 8 Loss: 2.273790\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6363/10000 (64%)\n",
            "63.63\n",
            "Train Epoch: 9 Loss: 2.273838\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6316/10000 (63%)\n",
            "63.16\n",
            "Train Epoch: 10 Loss: 2.273766\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6259/10000 (63%)\n",
            "62.59\n",
            "Train Epoch: 11 Loss: 2.273706\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6451/10000 (65%)\n",
            "64.51\n",
            "Train Epoch: 12 Loss: 2.273595\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6431/10000 (64%)\n",
            "64.31\n",
            "Train Epoch: 13 Loss: 2.273837\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6578/10000 (66%)\n",
            "65.78\n",
            "Train Epoch: 14 Loss: 2.273551\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6599/10000 (66%)\n",
            "65.99\n",
            "Train Epoch: 15 Loss: 2.273819\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6778/10000 (68%)\n",
            "67.78\n",
            "Train Epoch: 16 Loss: 2.273562\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6796/10000 (68%)\n",
            "67.96\n",
            "Train Epoch: 17 Loss: 2.273689\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6807/10000 (68%)\n",
            "68.07\n",
            "Train Epoch: 18 Loss: 2.273649\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6879/10000 (69%)\n",
            "68.79\n",
            "Train Epoch: 19 Loss: 2.273502\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6943/10000 (69%)\n",
            "69.43\n",
            "Train Epoch: 20 Loss: 2.273409\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7030/10000 (70%)\n",
            "70.3\n",
            "Train Epoch: 21 Loss: 2.273701\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7033/10000 (70%)\n",
            "70.33\n",
            "Train Epoch: 22 Loss: 2.273630\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6924/10000 (69%)\n",
            "69.24\n",
            "Train Epoch: 23 Loss: 2.273670\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7052/10000 (71%)\n",
            "70.52\n",
            "Train Epoch: 24 Loss: 2.273706\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7181/10000 (72%)\n",
            "71.81\n",
            "Train Epoch: 25 Loss: 2.273466\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7229/10000 (72%)\n",
            "72.29\n",
            "Train Epoch: 26 Loss: 2.273330\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7318/10000 (73%)\n",
            "73.18\n",
            "Train Epoch: 27 Loss: 2.273504\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7271/10000 (73%)\n",
            "72.71\n",
            "Train Epoch: 28 Loss: 2.273336\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7532/10000 (75%)\n",
            "75.32\n",
            "Train Epoch: 29 Loss: 2.273223\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7472/10000 (75%)\n",
            "74.72\n",
            "Train Epoch: 30 Loss: 2.273449\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7481/10000 (75%)\n",
            "74.81\n",
            "Train Epoch: 31 Loss: 2.273474\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7519/10000 (75%)\n",
            "75.19\n",
            "Train Epoch: 32 Loss: 2.273325\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7705/10000 (77%)\n",
            "77.05\n",
            "Train Epoch: 33 Loss: 2.273440\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7742/10000 (77%)\n",
            "77.42\n",
            "Train Epoch: 34 Loss: 2.273311\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7766/10000 (78%)\n",
            "77.66\n",
            "Train Epoch: 35 Loss: 2.273464\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7782/10000 (78%)\n",
            "77.82\n",
            "Train Epoch: 36 Loss: 2.273167\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7858/10000 (79%)\n",
            "78.58\n",
            "Train Epoch: 37 Loss: 2.273211\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7952/10000 (80%)\n",
            "79.52\n",
            "Train Epoch: 38 Loss: 2.273427\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7996/10000 (80%)\n",
            "79.96\n",
            "Train Epoch: 39 Loss: 2.273310\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8084/10000 (81%)\n",
            "80.84\n",
            "Train Epoch: 40 Loss: 2.273394\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8031/10000 (80%)\n",
            "80.31\n",
            "Train Epoch: 41 Loss: 2.273291\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8022/10000 (80%)\n",
            "80.22\n",
            "Train Epoch: 42 Loss: 2.273252\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8148/10000 (81%)\n",
            "81.48\n",
            "Train Epoch: 43 Loss: 2.273215\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8198/10000 (82%)\n",
            "81.98\n",
            "Train Epoch: 44 Loss: 2.273261\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8233/10000 (82%)\n",
            "82.33\n",
            "Train Epoch: 45 Loss: 2.273180\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8216/10000 (82%)\n",
            "82.16\n",
            "Train Epoch: 46 Loss: 2.273072\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8311/10000 (83%)\n",
            "83.11\n",
            "Train Epoch: 47 Loss: 2.273187\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8304/10000 (83%)\n",
            "83.04\n",
            "Train Epoch: 48 Loss: 2.273169\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8323/10000 (83%)\n",
            "83.23\n",
            "Train Epoch: 49 Loss: 2.273102\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8276/10000 (83%)\n",
            "82.76\n",
            "Train Epoch: 50 Loss: 2.273099\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8361/10000 (84%)\n",
            "83.61\n",
            "Train Epoch: 51 Loss: 2.273159\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8342/10000 (83%)\n",
            "83.42\n",
            "Train Epoch: 52 Loss: 2.273039\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8347/10000 (83%)\n",
            "83.47\n",
            "Train Epoch: 53 Loss: 2.273148\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8465/10000 (85%)\n",
            "84.65\n",
            "Train Epoch: 54 Loss: 2.273046\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8511/10000 (85%)\n",
            "85.11\n",
            "Train Epoch: 55 Loss: 2.273143\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8552/10000 (86%)\n",
            "85.52\n",
            "Train Epoch: 56 Loss: 2.273150\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8509/10000 (85%)\n",
            "85.09\n",
            "Train Epoch: 57 Loss: 2.272976\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8488/10000 (85%)\n",
            "84.88\n",
            "Train Epoch: 58 Loss: 2.272938\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8493/10000 (85%)\n",
            "84.93\n",
            "Train Epoch: 59 Loss: 2.273062\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8535/10000 (85%)\n",
            "85.35\n",
            "Train Epoch: 60 Loss: 2.273001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:29:20,415]\u001b[0m Trial 8 finished with value: 86.03 and parameters: {'useL1': 0.26182515280403906, 'useL2': 0.349625716329634, 'useBN': 6.638627796272163e-05, 'useDropout': 0.24968739428956332}. Best is trial 8 with value: 86.03.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8603/10000 (86%)\n",
            "86.03\n",
            "Train Epoch: 1 Loss: 2.302336\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6806/10000 (68%)\n",
            "68.06\n",
            "Train Epoch: 2 Loss: 2.291413\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 6529/10000 (65%)\n",
            "65.29\n",
            "Train Epoch: 3 Loss: 2.284100\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5947/10000 (59%)\n",
            "59.47\n",
            "Train Epoch: 4 Loss: 2.278512\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5215/10000 (52%)\n",
            "52.15\n",
            "Train Epoch: 5 Loss: 2.276135\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 5548/10000 (55%)\n",
            "55.48\n",
            "Train Epoch: 6 Loss: 2.275214\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6466/10000 (65%)\n",
            "64.66\n",
            "Train Epoch: 7 Loss: 2.274267\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6473/10000 (65%)\n",
            "64.73\n",
            "Train Epoch: 8 Loss: 2.273848\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6456/10000 (65%)\n",
            "64.56\n",
            "Train Epoch: 9 Loss: 2.273612\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6453/10000 (65%)\n",
            "64.53\n",
            "Train Epoch: 10 Loss: 2.273530\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6460/10000 (65%)\n",
            "64.6\n",
            "Train Epoch: 11 Loss: 2.273816\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6556/10000 (66%)\n",
            "65.56\n",
            "Train Epoch: 12 Loss: 2.273636\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6873/10000 (69%)\n",
            "68.73\n",
            "Train Epoch: 13 Loss: 2.273438\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6807/10000 (68%)\n",
            "68.07\n",
            "Train Epoch: 14 Loss: 2.273459\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6932/10000 (69%)\n",
            "69.32\n",
            "Train Epoch: 15 Loss: 2.273615\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 6947/10000 (69%)\n",
            "69.47\n",
            "Train Epoch: 16 Loss: 2.273360\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7050/10000 (70%)\n",
            "70.5\n",
            "Train Epoch: 17 Loss: 2.273413\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7140/10000 (71%)\n",
            "71.4\n",
            "Train Epoch: 18 Loss: 2.273600\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7231/10000 (72%)\n",
            "72.31\n",
            "Train Epoch: 19 Loss: 2.273308\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7199/10000 (72%)\n",
            "71.99\n",
            "Train Epoch: 20 Loss: 2.273216\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7222/10000 (72%)\n",
            "72.22\n",
            "Train Epoch: 21 Loss: 2.273368\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7210/10000 (72%)\n",
            "72.1\n",
            "Train Epoch: 22 Loss: 2.273422\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7348/10000 (73%)\n",
            "73.48\n",
            "Train Epoch: 23 Loss: 2.273267\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7297/10000 (73%)\n",
            "72.97\n",
            "Train Epoch: 24 Loss: 2.273344\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7455/10000 (75%)\n",
            "74.55\n",
            "Train Epoch: 25 Loss: 2.273368\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7490/10000 (75%)\n",
            "74.9\n",
            "Train Epoch: 26 Loss: 2.273278\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7514/10000 (75%)\n",
            "75.14\n",
            "Train Epoch: 27 Loss: 2.273299\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7611/10000 (76%)\n",
            "76.11\n",
            "Train Epoch: 28 Loss: 2.273239\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7638/10000 (76%)\n",
            "76.38\n",
            "Train Epoch: 29 Loss: 2.273258\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7621/10000 (76%)\n",
            "76.21\n",
            "Train Epoch: 30 Loss: 2.273103\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7693/10000 (77%)\n",
            "76.93\n",
            "Train Epoch: 31 Loss: 2.273377\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7685/10000 (77%)\n",
            "76.85\n",
            "Train Epoch: 32 Loss: 2.273262\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7705/10000 (77%)\n",
            "77.05\n",
            "Train Epoch: 33 Loss: 2.273287\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7913/10000 (79%)\n",
            "79.13\n",
            "Train Epoch: 34 Loss: 2.273165\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7941/10000 (79%)\n",
            "79.41\n",
            "Train Epoch: 35 Loss: 2.273119\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 7960/10000 (80%)\n",
            "79.6\n",
            "Train Epoch: 36 Loss: 2.273242\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8005/10000 (80%)\n",
            "80.05\n",
            "Train Epoch: 37 Loss: 2.273270\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8023/10000 (80%)\n",
            "80.23\n",
            "Train Epoch: 38 Loss: 2.273226\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8114/10000 (81%)\n",
            "81.14\n",
            "Train Epoch: 39 Loss: 2.273144\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8148/10000 (81%)\n",
            "81.48\n",
            "Train Epoch: 40 Loss: 2.273121\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8127/10000 (81%)\n",
            "81.27\n",
            "Train Epoch: 41 Loss: 2.273053\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8060/10000 (81%)\n",
            "80.6\n",
            "Train Epoch: 42 Loss: 2.273113\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8242/10000 (82%)\n",
            "82.42\n",
            "Train Epoch: 43 Loss: 2.273076\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8197/10000 (82%)\n",
            "81.97\n",
            "Train Epoch: 44 Loss: 2.273121\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8223/10000 (82%)\n",
            "82.23\n",
            "Train Epoch: 45 Loss: 2.273048\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8259/10000 (83%)\n",
            "82.59\n",
            "Train Epoch: 46 Loss: 2.273143\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8307/10000 (83%)\n",
            "83.07\n",
            "Train Epoch: 47 Loss: 2.273058\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8329/10000 (83%)\n",
            "83.29\n",
            "Train Epoch: 48 Loss: 2.273096\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8392/10000 (84%)\n",
            "83.92\n",
            "Train Epoch: 49 Loss: 2.273004\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8399/10000 (84%)\n",
            "83.99\n",
            "Train Epoch: 50 Loss: 2.273016\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8394/10000 (84%)\n",
            "83.94\n",
            "Train Epoch: 51 Loss: 2.273049\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8446/10000 (84%)\n",
            "84.46\n",
            "Train Epoch: 52 Loss: 2.273048\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8430/10000 (84%)\n",
            "84.3\n",
            "Train Epoch: 53 Loss: 2.273140\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8462/10000 (85%)\n",
            "84.62\n",
            "Train Epoch: 54 Loss: 2.272995\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8491/10000 (85%)\n",
            "84.91\n",
            "Train Epoch: 55 Loss: 2.272954\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8549/10000 (85%)\n",
            "85.49\n",
            "Train Epoch: 56 Loss: 2.273040\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8485/10000 (85%)\n",
            "84.85\n",
            "Train Epoch: 57 Loss: 2.272991\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8474/10000 (85%)\n",
            "84.74\n",
            "Train Epoch: 58 Loss: 2.272901\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8530/10000 (85%)\n",
            "85.3\n",
            "Train Epoch: 59 Loss: 2.272979\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8539/10000 (85%)\n",
            "85.39\n",
            "Train Epoch: 60 Loss: 2.272913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-23 21:31:36,304]\u001b[0m Trial 9 finished with value: 85.54 and parameters: {'useL1': 1.3831164197303696, 'useL2': 0.01714319674534926, 'useBN': 2.270824174542475e-05, 'useDropout': 0.1709245212520233}. Best is trial 8 with value: 86.03.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 8554/10000 (86%)\n",
            "85.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoKvaJv5tSVM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "db39c55d-f30d-42d7-aa70-1c120e35b113"
      },
      "source": [
        "df = study.trials_dataframe()\r\n",
        "df.head(5)\r\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"b948e175-9559-4ede-98a7-5df3be04a067\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"b948e175-9559-4ede-98a7-5df3be04a067\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'b948e175-9559-4ede-98a7-5df3be04a067',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [82.21, 82.37, 85.8, 79.0, 85.53, 85.0, 79.58, 81.51, 86.03, 85.54]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [82.21, 82.37, 85.8, 85.8, 85.8, 85.8, 85.8, 85.8, 86.03, 86.03]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b948e175-9559-4ede-98a7-5df3be04a067');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmevE3CTtWMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb2cb2a-f538-4a1e-f420-66d62d06542a"
      },
      "source": [
        "study.best_trial"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenTrial(number=8, values=[86.03], datetime_start=datetime.datetime(2021, 2, 23, 21, 27, 5, 248685), datetime_complete=datetime.datetime(2021, 2, 23, 21, 29, 20, 415602), params={'useL1': 0.26182515280403906, 'useL2': 0.349625716329634, 'useBN': 6.638627796272163e-05, 'useDropout': 0.24968739428956332}, distributions={'useL1': UniformDistribution(high=1.5, low=0.001), 'useL2': UniformDistribution(high=1.5, low=0.001), 'useBN': UniformDistribution(high=0.0001, low=1e-06), 'useDropout': UniformDistribution(high=0.55, low=0.01)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=8, state=TrialState.COMPLETE, value=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niB4r7Fhtkwr"
      },
      "source": [
        "Again, we can check learning curves in tensorboard ..\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsK_XdFJtkSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b9289c-a5cb-4347-9b08-83c38ae5bdf7"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eswEIXkjtfnp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "9c93532a-e41b-492b-fbee-539bb7c0dca0"
      },
      "source": [
        "%tensorboard --logdir 'runs_optuna'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6007, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSF6n1B9taNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd52c682-a01c-43bb-e9df-f39fb28df3ec"
      },
      "source": [
        "from tensorboard import notebook\r\n",
        "notebook.display(height=1000) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting TensorBoard with logdir runs_optuna (started 0:00:01 ago; port 6007, pid 861).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6007, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '1000');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}